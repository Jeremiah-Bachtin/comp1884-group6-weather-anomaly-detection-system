{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing & Modelling Pipeline",
   "id": "3270268bc8661c52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.client import device_lib\n",
    "import joblib\n",
    "from utils.find_root import find_project_root\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime"
   ],
   "id": "58477b233b693cbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check GPU access for LSTM-AE training\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# test if GPU engages\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.matmul(a, a)\n",
    "print(b)"
   ],
   "id": "976f179833c79ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Freeze randomness for reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "id": "7d5dfedf7b031d1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Retrieve the project root dynamically and set it as working directory\n",
    "project_root = find_project_root()\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Define output directories for ML models\n",
    "MODEL_OUTPUT_DIR = \"outputs/modelling/models/\"\n",
    "MODEL_METADATA_DIR = \"outputs/modelling/metadata/\"\n",
    "MODEL_PREDICTIONS_DIR = \"outputs/modelling/predictions/\"\n",
    "MODEL_INPUT_DIR = \"data/processed/model_input/\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_METADATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_PREDICTIONS_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_INPUT_DIR, exist_ok=True)"
   ],
   "id": "cfb05f15378c0f1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 0 - Dataset Loading and Splitting\n",
    "\n",
    "**Goal**:\n",
    "Split the historical dataset into training and validation subsets while preserving time order. The training set was used for model fitting and retrospective scoring. The validation set was used for monitoring early stopping during LSTM-AE training and for Isolation Forest threshold evaluation. A separate test set was excluded due to limited duration.\n",
    "\n",
    "---\n",
    "**Data Splitting & Anomaly Masking Strategy**\n",
    "\n",
    "To avoid lookahead bias, we used **time-based splits** where models only learn from past data — a best practice in time-series anomaly detection (Trinh, 2022; Darban, 2024).\n",
    "\n",
    "For **Isolation Forest**:\n",
    "\n",
    "- During LSTM-AE training, we applied a **relaxed 3rd percentile threshold** with a cap of **9 anomalies per sequence** to mask noisy timestamps. This helped ensure the LSTM-AE learned from stable input patterns.\n",
    "- For the **validation set**, a stricter **1st percentile threshold** was combined with the same anomaly cap. As a result, the validation sequences remained more contaminated and better reflected borderline or residual anomalies (Antwarg et al., 2021; Wenig, 2022).\n",
    "\n",
    "For **retrospective labelling**, we reused the relaxed **3rd percentile** IF threshold but **did not apply anomaly caps**, to reflect how the system would operate in deployment.\n",
    "\n",
    "This strategy maintains a balance between **clean model training** and **realistic anomaly scoring**, enabling more effective downstream hybrid labelling and interpretability.\n"
   ],
   "id": "ef333c5415a84e6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 0.1 Load dataset\n",
    "DATASET_PATH = \"data/processed/historical_merged/historical_IFS_merged_201702_to_202504.csv\"\n",
    "df = pd.read_csv(DATASET_PATH, parse_dates=['date'], index_col='date')\n",
    "df = df.asfreq('h')\n",
    "df.head()"
   ],
   "id": "60767d4fe407dda8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 0.2: Define chronological splits\n",
    "train_start, train_end = \"2017-02-01\", \"2025-01-31\"\n",
    "val_start, val_end = \"2025-02-01\", \"2025-04-30\"\n",
    "\n",
    "# Step 0.3: Subset dataframe\n",
    "df_train = df.loc[train_start:train_end]\n",
    "df_val = df.loc[val_start:val_end]\n",
    "\n",
    "print(f\"Training set: {len(df_train)} rows (~{len(df_train)/24:.0f} days; ~{len(df_train)/24/30:.0f} months; ~{len(df_train)/24/30/12:.0f} years).\")\n",
    "print(f\"Validation set: {len(df_val)} rows (~{len(df_val)/24:.0f} days; ~{len(df_val)/24/30:.0f} months)).\")"
   ],
   "id": "e68be490ce218abe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 1 – Feature Transformation & Normalisation\n",
    "**Goal**: Convert raw hourly weather data into scale-stable, model-ready inputs using rolling statistics, smoothing, robust scaling, and log transforms. These steps were designed based on EDA insights and tailored to each model’s needs. They were consistently applied across training, validation, and inference phases. The transformation pipeline draws on recent best practices in time-series anomaly detection and climate-focused ML (Tawalkuli, 2024; Trinh, 2022; Darban, 2024; Bakhashwain, 2020).\n",
    "\n",
    "---\n",
    "**Isolation Forest Inputs**\n",
    "\n",
    "- **Temperature & Surface Pressure**\n",
    "  These variables show smooth seasonal trends and daily cycles. We applied a **60-day rolling z-score**, allowing the model to focus on short-lived fluctuations over long-term drifts (Tawalkuli, 2024; Kulkarni, 2024; Almuqati, 2024).\n",
    "\n",
    "- **Wind Speed**\n",
    "  Wind is highly variable. To reduce noise, a **3-hour moving average** was applied, followed by **60-day IQR scaling**, which preserves ramps and gusts while filtering micro-spikes (Tawalkuli, 2024; Yang, 2023; Trinh, 2022).\n",
    "\n",
    "- **Precipitation**\n",
    "  Rainfall is sparse and skewed. We applied a **log1p transform** to dampen extreme values (Trinh, 2022; Darban, 2024). Then, **12-hour and 24-hour rolling z-scores** were computed to detect both gradual frontal systems and sudden convective spikes (Bâra, 2024; Almansoori, 2023).\n",
    "\n",
    "---\n",
    "\n",
    "**LSTM-AE Inputs**\n",
    "\n",
    "- **Temperature, Surface Pressure, Wind Speed:**<br>\n",
    "  These were **robustly scaled per 720-hour sequence** using **median and IQR**, making the LSTM more resilient to outliers during training (Antwarg, 2021; Yang, 2023; Liu, 2020).\n",
    "\n",
    "- **Precipitation**\n",
    "  Kept in its **log-transformed** form without further scaling. Its sparsity and episodic nature made standardisation unsuitable (Trinh, 2022; Darban, 2024).\n",
    "\n",
    "- **Cyclical Features** (engineered later in Step 2) were retained as **sine and cosine pairs** for hour and month to support temporal learning.\n",
    "\n",
    "---\n",
    "\n",
    "These pre-processing steps ensure the Isolation Forest receives normalised, scale-aware features and the LSTM-AE learns on stable, context-aware sequences — reducing false positives and improving anomaly sensitivity (Almansoori, 2023; Liu, 2020; Wenig, 2022).\n"
   ],
   "id": "9dea03d38c672716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.1: Select features (precautionary)\n",
    "raw_features = ['temperature_2m', 'surface_pressure', 'wind_speed_10m', 'precipitation']\n",
    "df_train = df_train[raw_features].copy()\n",
    "df_val =df_val[raw_features].copy()"
   ],
   "id": "2c8d300fbbea98a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.2: Set parameters for normalisation\n",
    "window_60d = 1440 # rolling window size; 60-day window captures seasonal baselines for IF\n",
    "min_periods_60d = 720 # minimum number of observations required for rolling calculations\n",
    "window_12h = 12 # rolling window size for 12-hour rolling z-score; 12h captures local volatility for sparse events like precipitation\n",
    "window_24h = 24 # rolling window size for 24-hour rolling z-score; 24h isolates larger spikes\n",
    "min_periods_12h = 6 # minimum number of observations required for rolling calculations for 12-hour rolling z-score\n",
    "min_periods_24h = 12 # minimum number of observations required for rolling calculations for 24-hour rolling z-score\n",
    "eps = 1e-6  # to avoid division by zero in rolling scaling calculations for precipitation and wind"
   ],
   "id": "5d2ec316bef20aa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.3 Temperature and Surface Pressure: 60-day rolling z-scores\n",
    "for col in ['temperature_2m', 'surface_pressure']:\n",
    "    # Train set\n",
    "    mean_train = df_train[col].rolling(window=window_60d, min_periods=min_periods_60d).mean()\n",
    "    std_train = df_train[col].rolling(window=window_60d, min_periods=min_periods_60d).std()\n",
    "    df_train[f'{col}_z'] = (df_train[col] - mean_train) / (std_train + eps)\n",
    "\n",
    "    # Validation set\n",
    "    mean_val = df_val[col].rolling(window=window_60d, min_periods=min_periods_60d).mean()\n",
    "    std_val = df_val[col].rolling(window=window_60d, min_periods=min_periods_60d).std()\n",
    "    df_val[f'{col}_z'] = (df_val[col] - mean_val) / (std_val + eps)"
   ],
   "id": "bc84cfd05204cbc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.4: Apply smoothing to wind speed (NO Z-SCORE)\n",
    "df_train['wind_r'] = df_train['wind_speed_10m'].rolling(window=3, min_periods=1).mean()\n",
    "df_val['wind_r']   = df_val['wind_speed_10m'].rolling(window=3, min_periods=1).mean()\n"
   ],
   "id": "17b5f5f5f0253eb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.5: Apply IQR scaling to smoothed Wind Speed\n",
    "for df_ in [df_train, df_val]:\n",
    "    med = df_['wind_r'].rolling(window=window_60d, min_periods=min_periods_60d).median()\n",
    "    q75 = df_['wind_r'].rolling(window=window_60d, min_periods=min_periods_60d).quantile(0.75)\n",
    "    q25 = df_['wind_r'].rolling(window=window_60d, min_periods=min_periods_60d).quantile(0.25)\n",
    "    iqr = q75 - q25\n",
    "    df_['wind_r'] = (df_['wind_r'] - med) / (iqr + eps)"
   ],
   "id": "3d0ca443167bdc1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.6: Tranform Precipitation with log1p\n",
    "# Log transformation reduces skew\n",
    "\n",
    "df_train['precip_log'] = np.log1p(df_train['precipitation'])\n",
    "df_val['precip_log']   = np.log1p(df_val['precipitation'])"
   ],
   "id": "a7e2883456b02cec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.7: Apply 12-hour z-score to logged Precipitation\n",
    "# short rolling window captures bursts\n",
    "\n",
    "for df in [df_train, df_val]:\n",
    "    # 12-hour rolling z-score\n",
    "    mean_12h = df['precip_log'].rolling(window=window_12h, min_periods=min_periods_12h).mean()\n",
    "    std_12h  = df['precip_log'].rolling(window=window_12h, min_periods=min_periods_12h).std()\n",
    "    df['precip_z_12h'] = (df['precip_log'] - mean_12h) / (std_12h + eps)\n",
    "\n",
    "    # 24-hour rolling z-score\n",
    "    mean_24h = df['precip_log'].rolling(window=window_24h, min_periods=min_periods_24h).mean()\n",
    "    std_24h  = df['precip_log'].rolling(window=window_24h, min_periods=min_periods_24h).std()\n",
    "    df['precip_z_24h'] = (df['precip_log'] - mean_24h) / (std_24h + eps)"
   ],
   "id": "bee59eb8e3e270fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1.8: Remove rows with NaNs (no rolling stats available for z-scores or IQRs - incomplete z-score/IQR minimum window)\n",
    "df_train = df_train.dropna().copy()\n",
    "df_val = df_val.dropna().copy()\n",
    "\n",
    "print(f\"Training rows after trimming: {len(df_train)}\")\n",
    "print(f\"Validation rows after trimming: {len(df_val)}\")"
   ],
   "id": "6317915dd5ab4c03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2 – Time-Based Feature Engineering\n",
    "**Goal**: add time features to help models learn daily and seasonal weather rhythms:\n",
    "\n",
    "- Hour of Day helps capture daily cycles, such as afternoon wind peaks or early morning pressure dips.\n",
    "\n",
    "- Month of Year reflects broader seasonal shifts, including temperature and rainfall patterns.\n",
    "\n",
    "These features are encoded using sine and cosine functions to preserve continuity (e.g. 23:00 and 00:00 are close). They are **excluded from the Isolation Forest**, which does not model sequence or cyclic behaviour (Molnar, 2025; Wenig, 2022). Instead, they **support sequential learning in LSTM-AE** (Trinh, 2022; Yang, 2023)."
   ],
   "id": "4e52b22581eec607"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2.1: Encode Hour-of-Day Cyclically\n",
    "# Extract hour of day and encode as sine/cosine\n",
    "df_train['hour'] = df_train.index.hour\n",
    "df_train['hour_sin'] = np.sin(2 * np.pi * df_train['hour'] / 24)\n",
    "df_train['hour_cos'] = np.cos(2 * np.pi * df_train['hour'] / 24)\n",
    "\n",
    "df_val['hour'] = df_val.index.hour\n",
    "df_val['hour_sin'] = np.sin(2 * np.pi * df_val['hour'] / 24)\n",
    "df_val['hour_cos'] = np.cos(2 * np.pi * df_val['hour'] / 24)"
   ],
   "id": "b8a46ead6a31351d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2.2: Encode Month-of-Year Cyclically\n",
    "\n",
    "# Extract month and encode as sine/cosine\n",
    "df_train['month'] = df_train.index.month\n",
    "df_train['month_sin'] = np.sin(2 * np.pi * df_train['month'] / 12)\n",
    "df_train['month_cos'] = np.cos(2 * np.pi * df_train['month'] / 12)\n",
    "\n",
    "df_val['month'] = df_val.index.month\n",
    "df_val['month_sin'] = np.sin(2 * np.pi * df_val['month'] / 12)\n",
    "df_val['month_cos'] = np.cos(2 * np.pi * df_val['month'] / 12)"
   ],
   "id": "9f9190fb1022f037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2.3: Define input features for Isolation Forest and LSTM-AE\n",
    "\n",
    "# Isolsation Forest\n",
    "# Note we do not feed the temporal features to IF as it does not exploit cyclic structure (Molnar, 2025)\n",
    "if_features = ['temperature_2m_z', 'surface_pressure_z', 'wind_r', 'precip_z_12h', 'precip_z_24h']\n",
    "\n",
    "# LSTM\n",
    "lstm_features = ['temperature_2m', 'surface_pressure', 'wind_speed_10m', 'precip_log'] # scaled per sequence later\n",
    "lstm_time_features = ['hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
    "lstm_input_cols_all = lstm_features + lstm_time_features"
   ],
   "id": "ee2bcc8a823906e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3 – Isolation Forest Training and Anomaly Scoring\n",
    "**Goal**: Train an Isolation Forest model using the transformed features in if_features.\n",
    "Use the model to compute anomaly scores for both the training and validation sets.\n",
    "Later, the same model will be used for inference on forecast data.\n",
    "> <span style=\"color: red;\"> Note: due to the randomness freeze earlier, IF reproduces the same results provided no changes are made above this cell. The LSTM-AE training is commented out for reproducibility due to slight changes during each retraining cycle on account of the reasons discussed in the LSTM-AE Training Summary section."
   ],
   "id": "5d52fd9dfebd561b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3.1: Define IF training set\n",
    "X_train_if = df_train[if_features]"
   ],
   "id": "f3f67cc2fbd0cadd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Isolation Forest Hyperparameter Justification**\n",
    "\n",
    "We used `n_estimators=100` and `contamination=0.01` in line with good practice for weather-related anomaly detection:\n",
    "\n",
    "- **`n_estimators=100`**\n",
    "  This controls how many isolation trees are built. Using 100 is a common and efficient choice that offers reliable results without adding much runtime. It is widely accepted in both published experiments and scikit-learn defaults, and supported in project work by Almansoori (2023) and Wenig (2022).\n",
    "\n",
    "- **`contamination=0.01`**\n",
    "  This sets the expected proportion of anomalies to 1%, which is typical for environmental datasets. Several recent studies (e.g. Almuqati, 2024; Almansoori, 2023) recommend values in this range to avoid false positives while keeping the model sensitive to rare, significant deviations.\n",
    "\n",
    "These settings allow for stable training, generalisable performance, and efficient use of resources in the hybrid anomaly detection pipeline."
   ],
   "id": "249075755276b282"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3.2: Train Isolation Forest model\n",
    "# Fit IF model on training data\n",
    "if_model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "if_model.fit(X_train_if)"
   ],
   "id": "e8251ae3c30018e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3.3: Save model\n",
    "\n",
    "# Get current timestamp in desired format, e.g., 20240605_1130\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Construct filename with timestamp\n",
    "model_filename = f\"if_model_{current_time}.joblib\"\n",
    "\n",
    "# Save model\n",
    "joblib.dump(if_model, os.path.join(MODEL_OUTPUT_DIR, model_filename))\n",
    "\n",
    "print(f\"✅ Model saved as {model_filename}\")"
   ],
   "id": "8a140aca6ab15d74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3.4: Apply the trained IF model to compute anomaly scores\n",
    "\n",
    "# Scores: higher = more normal, lower = more anomalous\n",
    "scores_train = if_model.decision_function(df_train[if_features])\n",
    "scores_val   = if_model.decision_function(df_val[if_features])\n",
    "\n",
    "# Attach scores to DataFrames\n",
    "df_train['if_score'] = scores_train\n",
    "df_val['if_score']   = scores_val"
   ],
   "id": "46a4c7572c497580"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 4 – Anomaly Masking via Percentile Thresholds\n",
    "\n",
    "**Goal**: Convert continuous Isolation Forest scores into binary anomaly flags using fixed percentile thresholds.\n",
    "\n",
    "Two thresholds are used:\n",
    "\n",
    "- **3rd percentile**: Applied to the training set. This cut-off flags more timestamps as anomalous, so fewer are considered normal. When paired with our rule of allowing a maximum of `n` anomalies per 720-hour sequence, this results in **stricter filtering** — retaining only the cleanest sequences. This is important for hybrid anomaly pipelines, where clean input is essential for teaching the LSTM-AE stable baseline patterns (Darban, 2024; Trinh, 2022).\n",
    "\n",
    "- **1st percentile**: Applied to the validation set. This threshold flags fewer points as anomalous, so more timestamps are retained. When the same `n`-anomaly rule is applied, **more sequences pass through**, allowing us to test the model on slightly noisier, more realistic patterns. This setup supports broader anomaly evaluation with controlled contamination, as recommended by Almansoori (2023), Bara (2024), and Wenig (2022).\n",
    "\n",
    "> While the 3rd percentile may appear “looser” numerically, it actually results in **stricter sequence-level filtering**.\n",
    "This design is intentional: we filter **aggressively for training**, to keep it clean, and **allow more variety in validation**, to evaluate robustness.\n"
   ],
   "id": "40a01d9a7c868ddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 4.1: Define percentile thresholds for anomaly masking\n",
    "\n",
    "mask_threshold_train = 3    # Bottom 3% most anomalous points in validation, will flag more anomalies\n",
    "mask_threshold_val = 1  # Bottom 1% most anomalous points in training, will flag fewer anomalies"
   ],
   "id": "8369e9c5b1628b15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 4.2: Apply Thresholds and Assign Flags\n",
    "\n",
    "# Training set masking (relaxed)\n",
    "if_threshold_train = np.percentile(scores_train, mask_threshold_train)\n",
    "df_train[\"is_if_anomaly\"] = df_train[\"if_score\"] < if_threshold_train\n",
    "\n",
    "# Validation set masking (strict)\n",
    "if_threshold_val = np.percentile(scores_val, mask_threshold_val)\n",
    "df_val[\"is_if_anomaly\"] = df_val[\"if_score\"] < if_threshold_val"
   ],
   "id": "b62242c4b9878bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f'Train: {if_threshold_train}, Val: {if_threshold_val}')",
   "id": "eeef8af083e06daf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 4.3: Sanity check: How many anomalies were flagged in training and validation?\n",
    "\n",
    "train_anomaly_counts = df_train['is_if_anomaly'].value_counts()\n",
    "val_anomaly_counts = df_val['is_if_anomaly'].value_counts()\n",
    "\n",
    "# Absolute counts\n",
    "print(\"Training Set Anomaly Counts:\")\n",
    "print(train_anomaly_counts)\n",
    "\n",
    "print(\"\\nValidation Set Anomaly Counts:\")\n",
    "print(val_anomaly_counts)\n",
    "\n",
    "# Proportions (percent of total)\n",
    "train_anomaly_ratio = df_train['is_if_anomaly'].mean()\n",
    "val_anomaly_ratio = df_val['is_if_anomaly'].mean()\n",
    "\n",
    "print(f\"\\nProportion of anomalies in training set: {train_anomaly_ratio:.4f} ({train_anomaly_ratio*100:.2f}%)\")\n",
    "print(f\"Proportion of anomalies in validation set: {val_anomaly_ratio:.4f} ({val_anomaly_ratio*100:.2f}%)\")"
   ],
   "id": "fe3dfa8a8e1d60e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 4.4: Plot anomaly scores for training and validation sets and their corresponding anomaly thresholds\n",
    "\n",
    "# Extract existing scores and thresholds (already defined earlier)\n",
    "train_scores = df_train['if_score'].values\n",
    "val_scores = df_val['if_score'].values\n",
    "\n",
    "# if_threshold_train and if_threshold_val are already defined using 1st and 3rd percentiles\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "axs[0].hist(train_scores, bins=100, color='skyblue', edgecolor='black')\n",
    "axs[0].axvline(if_threshold_train, color='blue', linestyle='--', label='3% Threshold')\n",
    "axs[0].set_title(\"Training Set IF Anomaly Scores\")\n",
    "axs[0].set_xlabel(\"Anomaly Score\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].hist(val_scores, bins=100, color='salmon', edgecolor='black')\n",
    "axs[1].axvline(if_threshold_val, color='red', linestyle='--', label='1% Threshold')\n",
    "axs[1].set_title(\"Validation Set IF Anomaly Scores\")\n",
    "axs[1].set_xlabel(\"Anomaly Score\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "82223bd40e818eb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***Interpreting Historgrams for Isolation Forest Score Thresholds***\n",
    "\n",
    "These plots help explain how the 3% and 1% anomaly thresholds were applied to the training and validation sets.\n",
    "\n",
    "- In the **training set**, the blue dashed line shows the **3% cut-off** (resting around 0.033), allowing a slightly broader range of less typical values to pass through.\n",
    "- In the **validation set**, the red dashed line marks the **1% threshold** (around the 0.008 mark), where only the most extreme points (far left tail) were flagged as anomalies.\n",
    "\n",
    "This approach supports our filtering logic — keeping LSTM-AE training focused on the cleaner sequences while still testing it on acceptably contaminated patterns. The different shapes of the two distributions are due to the difference in dataset sizes and thresholds, which is expected."
   ],
   "id": "45954c90c722c541"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 5 – LSTM-AE Sequence Construction (Training)\n",
    "**Goal**: Extract 30-day (720-hour) sequences from the training set for the LSTM Autoencoder.\n",
    "Sequences must contain no NaNs and no more than 9 anomalous points (~1.25% of the sequence) to preserve training stability while retaining data coverage."
   ],
   "id": "6d90ae689a42eec9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 5.1: Visualise allowed anomalies per sequence vs sequence retention\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 720\n",
    "sequence_stride = 1\n",
    "max_anomaly_count_threshold = 30\n",
    "optimal_anomaly_count_threshold = 9 # empirically determined\n",
    "\n",
    "def efficient_retention_counts(df, sequence_length=sequence_length, stride=sequence_stride, max_threshold=max_anomaly_count_threshold):\n",
    "    \"\"\"\n",
    "    Computes how many clean sequences can be retained at each anomaly threshold.\n",
    "\n",
    "    Slides a rolling window across the dataset and checks how many timestamps\n",
    "    in each window are anomalous or NaN. For each threshold (0 to max),\n",
    "    it counts how many windows pass the test.\n",
    "\n",
    "    Parameters:\n",
    "        df : pd.DataFrame – Must include 'is_if_anomaly' and contain NaNs where data is missing.\n",
    "        sequence_length : int – Number of time steps per sequence (default: 720).\n",
    "        stride : int – Currently unused (default: 1).\n",
    "        max_threshold : int – Highest anomaly count to check (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        thresholds : List[int] – Tested anomaly thresholds.\n",
    "        retention_counts : List[int] – Retained sequences for each threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    is_anomaly = df['is_if_anomaly'].values.astype(int)\n",
    "    has_nan = df[lstm_input_cols_all].isna().any(axis=1).values\n",
    "\n",
    "    # Convolve to count NaNs and anomalies over rolling windows\n",
    "    rolling_nan = np.convolve(has_nan.astype(int), np.ones(sequence_length, dtype=int), 'valid')\n",
    "    rolling_anomalies = np.convolve(is_anomaly, np.ones(sequence_length, dtype=int), 'valid').astype(int)\n",
    "\n",
    "    thresholds = list(range(0, max_threshold + stride))\n",
    "    retention_counts = [\n",
    "        np.count_nonzero((rolling_anomalies <= t) & (rolling_nan == 0))\n",
    "        for t in thresholds\n",
    "    ]\n",
    "\n",
    "    return thresholds, retention_counts\n",
    "\n",
    "thresholds, retention_counts = efficient_retention_counts(df_train, sequence_length)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Max Anomalies': thresholds, 'Retained': retention_counts})\n",
    "\n",
    "# First derivative: gain per additional anomaly\n",
    "df['Gain'] = df['Retained'].diff().fillna(0)\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Max Anomalies Allowed per Sequence')\n",
    "ax1.set_ylabel('Retained Sequences', color=color)\n",
    "ax1.plot(df['Max Anomalies'], df['Retained'], marker='o', color=color, label='Retained Sequences')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot gain on secondary axis\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Gain (Δ Sequences)', color=color)\n",
    "ax2.plot(df['Max Anomalies'], df['Gain'], marker='x', color=color, linestyle='--', label='Gain per Step')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Add vertical line at likely sweet spot (e.g. 14)\n",
    "ax1.axvline(x=optimal_anomaly_count_threshold, linestyle='--', color='grey', label='Chosen Threshold (14)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title(\"Retained Sequences vs. Max Allowed Anomalies (with Gain per Step)\")\n",
    "plt.show()"
   ],
   "id": "b0560fc37a203b9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 5.2: Compute retention rates for each anomaly fliter threshold\n",
    "\n",
    "# Use real 'is_if_anomaly' flags from df_train\n",
    "is_anomaly = df_train['is_if_anomaly'].astype(int).values\n",
    "\n",
    "# Compute rolling count of anomalies over 720-hour sequences\n",
    "rolling_anomalies_real = np.convolve(is_anomaly, np.ones(sequence_length, dtype=int), 'valid')\n",
    "\n",
    "# Count retained sequences at each threshold\n",
    "thresholds_real = list(range(0, max_anomaly_count_threshold + 1))\n",
    "retained_real = [np.count_nonzero(rolling_anomalies_real <= t) for t in thresholds_real]\n",
    "\n",
    "# Format results\n",
    "df_retention_real = pd.DataFrame({\n",
    "    'Max Anomalies': thresholds_real,\n",
    "    'Retained Sequences': retained_real\n",
    "})\n",
    "df_retention_real['Gain'] = df_retention_real['Retained Sequences'].diff().fillna(0)\n",
    "\n",
    "df_retention_real"
   ],
   "id": "65b01bc0ad7381ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Max noise per sequence: {optimal_anomaly_count_threshold/sequence_length:.2%}\")",
   "id": "ca4cd0b3e663a9ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Choosing the Maximum Number of Anomalies Allowed per Sequence**\n",
    "\n",
    "**Goal**: To train the LSTM Autoencoder on stable, reliable sequences while retaining enough training data for effective learning.\n",
    "\n",
    "We selected `max_allowed_anomalies = 9` based on the following:\n",
    "\n",
    "1. **Model Capacity and Design**\n",
    "   Our LSTM Autoencoder contains around 65,000 parameters, which is considered lightweight by deep learning standards. According to general best practice (Kulkarni et al., 2024; Yang, 2023), a deep time-series model of this scale typically requires **2,000–5,000 sequences** for reliable training. By allowing up to 9 point anomalies per 720-hour sequence (~1.25% contamination), we retain **3,922 clean sequences**, which falls comfortably within this range.\n",
    "\n",
    "2. **Empirical Trade-off**\n",
    "   Our retention analysis (`df_retention_real`) showed that `max = 9` offers a strong compromise:\n",
    "   - Allows much more data than strict thresholds like `max = 5` (591 sequences),\n",
    "   - Avoids the noise introduced by looser limits like `max = 14` (14,206 sequences).\n",
    "   This setting achieves high data quality without sacrificing diversity or volume.\n",
    "\n",
    "3. **Backed by Research**\n",
    "   Recent studies (Trinh, 2022; Wenig, 2022; Antwarg et al., 2021) recommend:\n",
    "   - First filtering data using point anomaly detectors like Isolation Forest (we applied a 3rd percentile cut-off),\n",
    "   - Then applying a **sequence-level threshold** to retain only low-contamination windows for model training.\n",
    "   This dual-filtering strategy has been shown to improve model generalisation and reduce overfitting on anomalous noise.\n",
    "\n",
    "By setting `max_allowed_anomalies = 9`, we ensure the model learns from mostly normal patterns while still having enough training data to converge effectively. This approach aligns with both **our model architecture** and **best practices in unsupervised anomaly detection**."
   ],
   "id": "f9ee7e31f39bc77f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 5.3: Construct Clean Sequences for df_train\n",
    "\n",
    "max_allowed_anomalies = optimal_anomaly_count_threshold\n",
    "# Features to robustly scale\n",
    "features_to_scale = ['temperature_2m', 'surface_pressure', 'wind_speed_10m']\n",
    "feature_indices = [lstm_input_cols_all.index(f) for f in features_to_scale]\n",
    "\n",
    "# Define robust scaling function\n",
    "def robust_scale_sequence(sequence, feature_indices, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Applies robust scaling (median and IQR) to selected feature columns in a 2D sequence array.\n",
    "    \"\"\"\n",
    "    sequence = sequence.copy()\n",
    "    for i in feature_indices:\n",
    "        col = sequence[:, i]\n",
    "        median = np.median(col)\n",
    "        iqr = np.percentile(col, 75) - np.percentile(col, 25)\n",
    "        sequence[:, i] = (col - median) / (iqr + eps)\n",
    "    return sequence\n",
    "\n",
    "# Define clean sequence construction function\n",
    "def construct_lstm_sequences(\n",
    "    df,\n",
    "    sequence_length,\n",
    "    sequence_stride,\n",
    "    max_allowed_anomalies,\n",
    "    lstm_input_cols_all,\n",
    "    feature_indices,\n",
    "    desc_label=\"Constructing sequences\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Constructs LSTM-compatible sequences from a DataFrame using anomaly filtering and robust scaling.\n",
    "\n",
    "    Parameters:\n",
    "        df : pd.DataFrame\n",
    "            Input DataFrame with preprocessed features and 'is_if_anomaly' column.\n",
    "        sequence_length : int\n",
    "            Number of timesteps per sequence (e.g., 720 hours).\n",
    "        sequence_stride : int\n",
    "            Sliding window stride (e.g., 1 for full scan).\n",
    "        max_allowed_anomalies : int\n",
    "            Maximum number of anomalies permitted per sequence.\n",
    "        lstm_input_cols_all : list\n",
    "            Names of input features to extract and scale.\n",
    "        feature_indices : list\n",
    "            Index positions of features to robustly scale.\n",
    "        desc_label : str\n",
    "            Label for the tqdm progress bar (e.g., 'Training' or 'Validation').\n",
    "\n",
    "    Returns:\n",
    "        sequences : list of np.ndarray\n",
    "            Cleaned and scaled sequences.\n",
    "        sequence_starts : list of pd.Timestamp\n",
    "            Start timestamps of retained sequences.\n",
    "        debug_counts : dict\n",
    "            Count summary of evaluated, rejected, and accepted windows.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    is_anomaly = df['is_if_anomaly'].astype(bool).values\n",
    "    data_array = df[lstm_input_cols_all].values\n",
    "    index_array = df.index.values\n",
    "\n",
    "    total_windows = len(df) - sequence_length + 1\n",
    "    sequences = []\n",
    "    sequence_starts = []\n",
    "    debug_counts = {'total': 0, 'has_anomalies': 0, 'added': 0}\n",
    "\n",
    "    for start in tqdm(range(0, total_windows, sequence_stride), desc=f\"Step: {desc_label}\"):\n",
    "        end = start + sequence_length\n",
    "        debug_counts['total'] += 1\n",
    "\n",
    "        if np.count_nonzero(is_anomaly[start:end]) > max_allowed_anomalies:\n",
    "            debug_counts['has_anomalies'] += 1\n",
    "            continue\n",
    "\n",
    "        raw_seq = data_array[start:end]\n",
    "        scaled_seq = robust_scale_sequence(raw_seq, feature_indices)\n",
    "        sequences.append(scaled_seq)\n",
    "        sequence_starts.append(index_array[start])\n",
    "        debug_counts['added'] += 1\n",
    "\n",
    "    return sequences, sequence_starts, debug_counts\n",
    "\n",
    "# Run construction on df_train\n",
    "train_sequences, train_starts, train_debug = construct_lstm_sequences(\n",
    "    df_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sequence_stride=sequence_stride,\n",
    "    max_allowed_anomalies=optimal_anomaly_count_threshold,\n",
    "    lstm_input_cols_all=lstm_input_cols_all,\n",
    "    feature_indices=feature_indices,\n",
    "    desc_label=\"Training\"\n",
    ")\n",
    "\n",
    "# Safely expand and mark timestamps used in training\n",
    "train_used_timestamps = set()\n",
    "for start_time in train_starts:\n",
    "    train_used_timestamps.update(\n",
    "        pd.date_range(start=start_time, periods=sequence_length, freq='h')\n",
    "    )\n",
    "\n",
    "df_train[\"used_in_lstm_training\"] = df_train.index.isin(train_used_timestamps)\n",
    "\n",
    "# Print training stats\n",
    "print(\"Training sequence construction complete.\")\n",
    "print(f\"Window stats: {train_debug}\")\n",
    "print(f\"Training sequences: {len(train_sequences)}\")\n",
    "print(f\"Timestamps used in training: {len(train_used_timestamps)}\")\n",
    "print(df_train[\"used_in_lstm_training\"].value_counts(normalize=True))"
   ],
   "id": "113c882122145634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 5.4: Visualise sequence distribution and optimal anomaly filter threshold\n",
    "\n",
    "# Rolling anomaly count\n",
    "anomalies_per_window = (\n",
    "    df_train[\"is_if_anomaly\"]\n",
    "    .astype(int)\n",
    "    .rolling(window=sequence_length)\n",
    "    .sum()\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "# Stats\n",
    "num_clean_windows = (anomalies_per_window <= max_allowed_anomalies).sum()\n",
    "num_total_windows = len(anomalies_per_window)\n",
    "max_anomalies_seen = int(anomalies_per_window.max())\n",
    "\n",
    "# Define bin edges so that 0 starts at the y-axis\n",
    "bin_edges = np.arange(-0.5, max_anomalies_seen + 1.5, 1)\n",
    "\n",
    "# Plot histogram with centre-aligned bars\n",
    "plt.figure(figsize=(16, 5))\n",
    "counts, bins, patches = plt.hist(\n",
    "    anomalies_per_window,\n",
    "    bins=bin_edges,\n",
    "    align='mid',\n",
    "    color='steelblue',\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Set integer ticks aligned with bar centres\n",
    "plt.xticks(range(0, max_anomalies_seen + 1))\n",
    "\n",
    "# Threshold line\n",
    "plt.axvline(max_allowed_anomalies, color='red', linestyle='--',\n",
    "            label=f\"Max anomalies allowed = {max_allowed_anomalies}\")\n",
    "\n",
    "# Annotation\n",
    "plt.annotate(\n",
    "    f\"{num_clean_windows:,} sequences ≤ {max_allowed_anomalies}\\n({num_clean_windows / num_total_windows:.1%})\",\n",
    "    xy=(max_allowed_anomalies + 0.5, plt.ylim()[1] * 0.85),\n",
    "    color='black',\n",
    "    fontsize=11,\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", lw=1)\n",
    ")\n",
    "\n",
    "# Labels\n",
    "plt.title(f\"Anomalies per {sequence_length}-Hour Sequence\")\n",
    "plt.xlabel(\"Number of anomalies per sequence\")\n",
    "plt.ylabel(\"Number of sequences\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "795896a5f9b13900"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 5.5: Stack into model-ready tensor\n",
    "# Format: (n_sequences, 720, n_features)\n",
    "\n",
    "X_train_lstm = np.stack(train_sequences)\n",
    "print(f\"LSTM training sequences: {X_train_lstm.shape}\")"
   ],
   "id": "f402152be67002d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 6 – LSTM-AE Sequence Construction (Validation)\n",
    "**Goal**: Extract 720-hour sequences from the validation set using the same feature columns, stride and maximum bumber of IF anomalies as in training, while applying stricter masking, allowing more noise in for robust validation.\n",
    "This set is used for threshold tuning and early stopping during training."
   ],
   "id": "f2fbbdb76a342c81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"IF score stats (val):\", df_val[\"if_score\"].describe())\n",
    "print(\"Threshold used:\", if_threshold_val)\n",
    "print(\"Anomalies flagged:\", df_val[\"is_if_anomaly\"].sum())"
   ],
   "id": "537ec38ff58bf1a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 6.1: Construct Clean Sequences for df_val Using Shared Constructor\n",
    "\n",
    "# Reuse generalised LSTM sequence constructor\n",
    "val_sequences, val_sequence_starts, val_debug = construct_lstm_sequences(\n",
    "    df_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sequence_stride=sequence_stride,\n",
    "    max_allowed_anomalies=max_allowed_anomalies,\n",
    "    lstm_input_cols_all=lstm_input_cols_all,\n",
    "    feature_indices=feature_indices,\n",
    "    desc_label=\"Validation\"\n",
    ")\n",
    "\n",
    "# Expand and mark timestamps used in validation\n",
    "val_used_timestamps = set()\n",
    "for start_time in val_sequence_starts:\n",
    "    val_used_timestamps.update(\n",
    "        pd.date_range(start=start_time, periods=sequence_length, freq='h')\n",
    "    )\n",
    "\n",
    "df_val[\"used_in_lstm_validation\"] = df_val.index.isin(val_used_timestamps)\n",
    "\n",
    "# Print validation stats\n",
    "print(\"Validation sequence construction complete.\")\n",
    "print(f\"Validation window stats: {val_debug}\")\n",
    "print(f\"Validation sequences: {len(val_sequences)}\")\n",
    "print(f\"Timestamps used in validation: {len(val_used_timestamps)}\")\n",
    "print(df_val[\"used_in_lstm_validation\"].value_counts(normalize=True))"
   ],
   "id": "352574351cc1f976"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Concise summary\n",
    "print(f\"{val_debug['added']} accepted sequences\")\n",
    "print(f\"{df_val['used_in_lstm_validation'].sum()} timestamps used in LSTM validation sequences (out of {len(df_val)})\")"
   ],
   "id": "242701122778a716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Sequences span from {min(val_used_timestamps)} to {max(val_used_timestamps)}\")",
   "id": "ed7090f82b20f51d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Validation Sequence Coverage Summary**\n",
    "\n",
    "A total of **593 validation sequences** were accepted for LSTM-AE evaluation. These sequences:\n",
    "\n",
    "- Span the period from **2nd March 25 to 30 April 2025**,\n",
    "- Are each **720 hours long (30 days)**, using a stride of 1,\n",
    "- Contain **no missing values** and **no more than 9 IF-flagged anomalies** (1.25% of a sequence),\n",
    "  where anomalies were defined using the **1st percentile** threshold.\n",
    "\n",
    "This filtering strategy ensures that the model is tested on **largely clean, realistic sequences** — not artificially perfect ones.\n",
    "This design aligns with best practices in hybrid anomaly detection pipelines:\n",
    "\n",
    "- **Trinh (2022)** recommends validating on sequences with **slight contamination**, to reflect real-world behaviour.\n",
    "- **Darban (2024)** supports tolerating **1–2% anomaly presence** in long validation windows to maintain generalisation integrity."
   ],
   "id": "dfc6aa2326e805f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 6.3: Final shape: (n_val_sequences, 720, n_features)\n",
    "\n",
    "X_val_lstm = np.stack(val_sequences)\n",
    "print(f\"LSTM validation sequences: {X_val_lstm.shape}\")"
   ],
   "id": "1b45877c9eca5c89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 7 – Save Processed Sequences and Transformed Data\n",
    "**Goal**: Persist key outputs including preprocessed training and validation dataframes, and their corresponding LSTM-AE tensors.\n",
    "This allows reuse for model training, threshold tuning, and interpretability tasks without re-running all preprocessing steps."
   ],
   "id": "b3e16829d51baae6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get current timestamp in desired format, e.g., 20240605_1130\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Save transformed DataFrames (optional but useful for SHAP/debugging)\n",
    "df_train.to_csv(os.path.join(MODEL_INPUT_DIR, f'df_train_preprocessed_{current_time}.csv'))\n",
    "df_val.to_csv(os.path.join(MODEL_INPUT_DIR, f'df_val_preprocessed_{current_time}.csv'))\n",
    "\n",
    "# Save LSTM-AE ready sequences\n",
    "np.save(os.path.join(MODEL_INPUT_DIR, f'X_train_lstm_{current_time}.npy'), X_train_lstm)\n",
    "np.save(os.path.join(MODEL_INPUT_DIR, f'X_val_lstm_{current_time}.npy'), X_val_lstm)"
   ],
   "id": "b5c17fd7013fbb02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 8 – Train the LSTM Autoencoder\n",
    "**Goal**: Train an LSTM-based autoencoder on the 720-hour sequences (X_train_lstm) to learn normal weather patterns.\n",
    "During evaluation, sequences that produce the highest reconstruction errors will be considered anomalous.\n",
    "\n",
    "**LSTM-AE Architecture: Parameter Justification**\n",
    "\n",
    "This autoencoder is designed to learn patterns in clean 30-day weather sequences and flag unusual ones by reconstruction error. The architecture balances compression, expressiveness, and training stability.\n",
    "\n",
    "- **Input Shape `(720, 8)`**\n",
    "  We use 30-day sequences with 8 features per time step (weather + time-based). This window length captures key seasonal and diurnal variation (Darban, 2024; Kulkarni, 2024).\n",
    "\n",
    "- **Encoder: 2 stacked LSTM layers `(64 → 32 units)`**\n",
    "  The first layer extracts local patterns, while the second compresses the full sequence into a single summary. Stacked LSTMs improve temporal abstraction, as recommended by Trinh (2022) and Bakhashwain (2020).\n",
    "\n",
    "- **Bottleneck: `RepeatVector(720)`**\n",
    "  This expands the compressed summary to match the original sequence length, giving the decoder enough context to reconstruct the sequence.\n",
    "\n",
    "- **Decoder: 2 LSTM layers `(32 → 64 units)`**\n",
    "  The decoder mirrors the encoder, gradually rebuilding the full sequence from the bottleneck vector. Matching the encoder-decoder depth improves symmetry and stability.\n",
    "\n",
    "- **Output Layer: `TimeDistributed(Dense(8))`**\n",
    "  A dense layer is applied to each time step to predict all 8 features. This setup ensures output shape matches the input for reconstruction.\n",
    "\n",
    "- **Activation Function: `tanh`**\n",
    "  `tanh` is suitable for time series data as it handles both positive and negative values and prevents exploding gradients in LSTMs (Trinh, 2022).\n",
    "\n",
    "- **Loss Function: `mae` (mean absolute error)**\n",
    "  MAE is less sensitive to outliers than MSE and is more interpretable for reconstruction-based anomaly detection (Darban, 2024).\n",
    "\n",
    "- **Optimiser: Adam with learning rate `0.001`**\n",
    "  Adam is widely used in sequence models for its stability and adaptability. A learning rate of 0.001 is a commonly recommended default (Bakhashwain, 2020).\n",
    "\n",
    "> This architecture provides a good trade-off between compression and reconstruction power, following established best practices in unsupervised time-series anomaly detection."
   ],
   "id": "c5e797c0ced872f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 8.1: Define the LSTM-AE Architecture\n",
    "\n",
    "# Get sequence and feature dimensions\n",
    "timesteps = X_train_lstm.shape[1]  # e.g. 720\n",
    "n_features = X_train_lstm.shape[2] # e.g. 8\n",
    "\n",
    "# Define model\n",
    "input_layer = Input(shape=(timesteps, n_features))\n",
    "\n",
    "# Encoder\n",
    "encoded = LSTM(64, activation='tanh', return_sequences=True)(input_layer)\n",
    "encoded = LSTM(32, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "# Bottleneck\n",
    "bottleneck = RepeatVector(timesteps)(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = LSTM(32, activation='tanh', return_sequences=True)(bottleneck)\n",
    "decoded = LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(n_features))(decoded)\n",
    "\n",
    "# Assemble\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
    "\n",
    "# Print summary\n",
    "autoencoder.summary()"
   ],
   "id": "48dd550c38ad24a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 9 – Train the LSTM Autoencoder with Early Stopping <br>\n",
    "**Goal**: Train the LSTM-AE to reconstruct normal sequences using MAE loss.\n",
    "Early stopping prevents overfitting by halting training when validation loss no longer improves."
   ],
   "id": "f4ce3b45a73eb073"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Training Configuration Summary**\n",
    "\n",
    "We trained the LSTM Autoencoder using the following settings:\n",
    "\n",
    "- Loss = 'mae' (Mean Absolute Error):\n",
    "- MAE is used to measure how closely the model can reconstruct each value in a sequence. It is more robust to outliers than MSE and works well for threshold-based anomaly detection (Trinh, 2022; Darban, 2024).\n",
    "\n",
    "- Batch size = 32:\n",
    "This is a typical batch size for time-series data. It allows the model to learn temporal dependencies while maintaining training efficiency (Kulkarni et al., 2024).\n",
    "\n",
    "- Epochs = 100 with early stopping (patience = 5):\n",
    "Early stopping halts training when the validation loss stops improving. This prevents overfitting and saves resources (Bâra et al., 2024).\n",
    "\n",
    "- ModelCheckpoint:\n",
    "We saved the best-performing model (based on validation loss) to a .h5 file for reuse. This avoids retraining and supports downstream analysis (Antwarg et al., 2021).\n",
    "\n",
    "- Shuffle = True:\n",
    "Shuffling training sequences prevents the model from overfitting to local trends and improves generalisation (Darban, 2024).\n",
    "\n",
    "> *Note*: Track GPU usage during training, enter `cmd` in Windows search and enter `nvidia-smi -l 5`"
   ],
   "id": "4fd960876632d8c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 9.1: Train LSTM Autoencoder (with Early Stopping & Timing)\n",
    "\n",
    "# Get current timestamp in desired format, e.g., 20240605_1130\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# UNCOMMENT BELOW FOR RETRAINING\n",
    "#\n",
    "# # Define callbacks\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#\n",
    "# model_checkpoint = ModelCheckpoint(\n",
    "#     filepath=f'{MODEL_OUTPUT_DIR}lstm_ae_best_{current_time}.h5',\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True,\n",
    "#     verbose=1\n",
    "# )\n",
    "#\n",
    "# # Start timing\n",
    "# start_time = time.time()\n",
    "# # Train the model\n",
    "# history = autoencoder.fit(\n",
    "#     X_train_lstm, X_train_lstm,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     validation_data=(X_val_lstm, X_val_lstm),\n",
    "#     callbacks=[early_stopping, model_checkpoint],\n",
    "#     shuffle=True,\n",
    "#     verbose=2\n",
    "# )\n",
    "#\n",
    "# # End timing\n",
    "# end_time = time.time()\n",
    "# total_time = end_time - start_time\n",
    "#\n",
    "# # Sequence Stats\n",
    "# n_train_seqs = X_train_lstm.shape[0]\n",
    "# n_val_seqs = X_val_lstm.shape[0]\n",
    "#\n",
    "# def get_gpu_info():\n",
    "#     devices = device_lib.list_local_devices()\n",
    "#     gpu_info = [d for d in devices if d.device_type == 'GPU']\n",
    "#     if gpu_info:\n",
    "#         print(\"\\nGPU Device Found:\")\n",
    "#         for d in gpu_info:\n",
    "#             print(f\"- {d.name} ({d.physical_device_desc})\")\n",
    "#     else:\n",
    "#         print(\"\\nNo GPU found. Training used CPU.\")\n",
    "#\n",
    "# # Print summary\n",
    "# print(f\"\\nTraining sequences: {n_train_seqs}\")\n",
    "# print(f\"Validation sequences: {n_val_seqs}\")\n",
    "# print(f\"Total training time: {total_time / 60:.2f} minutes\")\n",
    "#\n",
    "# get_gpu_info()"
   ],
   "id": "d199b802450267ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot training history\n",
    "\n",
    "# UNCOMMENT BELOW WHEN TRAINING\n",
    "\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# epochs = range(1, len(history.history['loss']) + 1)\n",
    "#\n",
    "# plt.plot(epochs, history.history['loss'], label='Train Loss')\n",
    "# plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
    "#\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"MAE Loss\")\n",
    "# plt.title(\"LSTM-AE Training Loss\")\n",
    "# plt.xticks(epochs)\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "id": "6dad4749f9b84cb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load LSMT-AT model handed off to XAI lead\n",
    "\n",
    "# !!!WARNING: COMMENT THE FOLLOWING LINE IF RETRAINING!!!\n",
    "autoencoder = load_model(os.path.join(MODEL_OUTPUT_DIR, f'lstm_ae_best.h5'))\n",
    "\n",
    "# Run Keras evaluation on validation set\n",
    "val_loss_keras = autoencoder.evaluate(X_val_lstm, X_val_lstm, verbose=1)\n",
    "\n",
    "print(f\"Confirmed Keras val_loss (MAE): {val_loss_keras:.4f}\")"
   ],
   "id": "f231536e83ca3996"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**LSTM-AE Training Summary**<br>\n",
    "<span style=\"color: red;\">*See below for reasons why results may vary slightly between retraining runs*</span>\n",
    "\n",
    "The LSTM Autoencoder was trained using early stopping (`patience = 5`) with validation MAE as the monitored metric. With randomness fixed across Python, NumPy, and TensorFlow, training was **reproducible within acceptable variance**:\n",
    "\n",
    "- **Initial validation loss:** 0.4089 (Epoch 1)\n",
    "- **Best validation loss:** 0.4046 (Epoch 12)\n",
    "- **Training loss range:** 0.4067 → 0.4297\n",
    "- **Validation loss range:** 0.4065 → 0.4180\n",
    "- **Final model saved at Epoch 12**\n",
    "\n",
    "Despite a smaller validation set (593 vs 3922 sequences) and minor noise due to sequence shuffling, **no signs of overfitting were observed**. The slight `val_loss` bumps (e.g. Epochs 10 and 15) are common with sequence data and do not indicate instability.\n",
    "\n",
    "The final **validation MAE of ~0.405** suggests **good generalisation**, while the training MAE (0.387) and the model’s ability to reconstruct known patterns confirm effective learning. This sits comfortably within the benchmark MAE range for 720-hour LSTM-AE weather sequences reported in similar anomaly detection studies (Trinh, 2022; Almansoori, 2023; Darban, 2024: *~0.38–0.45*).\n",
    "\n",
    "This confirms that the model is ready for anomaly scoring and SHAP-based XAI analysis.\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color: red;\">**Why LSTM-AE Training Results Might Differ Slightly Between Runs**</span>\n",
    "\n",
    "Even though we locked randomness (using seeds for Python, NumPy, TensorFlow, and enabling deterministic ops), **small differences** in training results still occurred. This is a known issue in deep learning, especially when using **GPU-accelerated LSTM layers**. Besides, using shuffle=True during training can still cause slightly different results each time because the order of training examples changes in a way that's not fully controllable.\n",
    "\n",
    "**Key reasons for variation in results**:\n",
    "\n",
    "- `random = True`\n",
    "- **cuDNN kernel variations:** TensorFlow uses cuDNN under the hood for fast LSTM training. These kernels are highly optimised but **not fully reproducible** across runs, even with fixed seeds (Antwarg et al., 2021; Trinh, 2022).\n",
    "- **Floating point maths:** Computers handle decimals differently depending on operation order. Tiny differences can add up over time (Kulkarni, 2024).\n",
    "- **GPU thread scheduling:** The GPU may process things in a slightly different order each time, especially under load — this also affects results.\n",
    "\n",
    "> Despite this, our results are **stable and reliable**, with final `val_loss` differences well under 0.005. This level of variation is widely accepted in research and does **not affect model quality or conclusions** (Almansoori, 2023; Bara, 2024)."
   ],
   "id": "39ce311cde3463a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 10: Evaluate the trained LSTM-AE model using the validation set\n",
    "\n",
    "**Goal**: The aim of this step is to evaluate how well the trained LSTM Autoencoder reconstructs the validation sequences, which may still include **mild contamination**. While both the training and validation sets were filtered using a **max-anomaly-per-sequence threshold**, the point-wise Isolation Forest thresholds differed:\n",
    "\n",
    "- `df_train` was filtered using a **3rd percentile IF cut-off** (more lenient),\n",
    "- `df_val` used a **stricter 1st percentile IF cut-off**.\n",
    "\n",
    "However, because both sets applied the **same sequence-level anomaly cap** (e.g. ≤9 anomalies), but `df_val` used a **stricter IF threshold (1st percentile)**, it retained sequences with **more severe anomalies**. These outliers were harder to flag under the strict cut-off, so the sequences that passed through contain **higher-impact contamination**, even if fewer in number. This makes `df_val` overall **more challenging and more contaminated** than `df_train`.\n",
    "\n",
    "To assess robustness, we calculate the **mean absolute error (MAE)** per timestamp by comparing original vs. reconstructed sequences. This enables:\n",
    "\n",
    "- Evaluation of the model on **semi-clean, real-world-like sequences**,\n",
    "- Detection of timestamp-level deviations that may indicate **pattern anomalies**,\n",
    "- Preparation of reconstruction scores for **hybrid anomaly labelling** and SHAP-style interpretability.\n",
    "\n",
    "This setup mirrors approaches in **Trinh (2022)**, **Kulkarni (2024)**, and **Bâra (2024)**, where LSTM-AE models are assessed on lightly contaminated sequences to simulate practical deployment conditions and set statistically grounded detection thresholds."
   ],
   "id": "1155b2b3d5cca575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 10.1 – Compute reconstruction errors and flatten to timestamp level\n",
    "\n",
    "# Predict with trained LSTM-AE\n",
    "recon_val = autoencoder.predict(np.array(val_sequences), verbose=1)\n",
    "\n",
    "# Compute MAE per timestep\n",
    "reconstruction_errors = np.mean(np.abs(np.array(val_sequences) - recon_val), axis=2)\n",
    "\n",
    "# Expand timestamps efficiently\n",
    "start_times_np = pd.to_datetime(val_sequence_starts).to_numpy()\n",
    "offsets = np.arange(sequence_length).astype(\"timedelta64[h]\")\n",
    "timestamps_array = start_times_np[:, None] + offsets  # shape: (n_sequences, 720)\n",
    "\n",
    "# Flatten\n",
    "flat_timestamps = timestamps_array.ravel()\n",
    "flat_errors = reconstruction_errors.ravel()\n",
    "\n",
    "# Assemble DataFrame\n",
    "df_lstm_recon_errors = pd.DataFrame({\n",
    "    'date': flat_timestamps,\n",
    "    'lstm_score': flat_errors\n",
    "}).sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Step 10.1 complete – Shape: {df_lstm_recon_errors.shape}\")"
   ],
   "id": "b5624ce54608af66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Why we need the mean MAE per timestamp**\n",
    "\n",
    "Each hour in the validation set may appear in multiple sequences due to the sliding window.\n",
    "\n",
    "To ensure each timestamp has one meaningful score, we compute the **mean reconstruction error (MAE) per timestamp**. This gives a fair, unbiased view of how well the model reconstructed that hour, in line with best practice for multistep time-series evaluation (Wenig, 2022; Darban, 2024).\n"
   ],
   "id": "45beafec7a7f52e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 10.1 continued: Compute mean LSTM-AE reconstruction error (MAE) per timestamp\n",
    "\n",
    "df_lstm_recon_errors_agg = (\n",
    "    df_lstm_recon_errors\n",
    "    .groupby('date')['lstm_score']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_lstm_recon_errors_agg[\"lstm_score\"].describe()"
   ],
   "id": "435b250819398ba5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 10.2: Plotting mean reconstruction errors per timestamp over time\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df_lstm_recon_errors_agg['date'], df_lstm_recon_errors_agg['lstm_score'], color='steelblue', linewidth=0.6)\n",
    "plt.title(\"LSTM-AE Reconstruction Error Over Time (Validation Set)\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Reconstruction Error (MAE)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c315de9d63af0e16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, we merge the per-timestamp LSTM-AE reconstruction error (`lstm_score`) into `df_val` to provide a unified DataFrame for anomaly scoring and downstream explainability.\n",
    "\n",
    "This ensures each row now contains:\n",
    "- Input weather features,\n",
    "- `if_score` and `is_if_anomaly` from Isolation Forest,\n",
    "- `lstm_score` from the Autoencoder.\n",
    "\n",
    "This merged structure supports hybrid labelling (e.g. compound anomaly detection), explainable AI attribution (e.g. TreeSHAP, IG), and dashboard reporting."
   ],
   "id": "92ac808e3f19e0f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_val",
   "id": "edd7e37b27d1142a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 10.3 Merge the LSTM-AE score (mean MAE per timestamp) into df_val\n",
    "\n",
    "# Join using timestamp alignment (df_val index is datetime-based)\n",
    "\n",
    "if 'lstm_score' in df_val.columns:\n",
    "    df_val.drop(columns='lstm_score', inplace=True)\n",
    "\n",
    "df_val = df_val.merge(\n",
    "    df_lstm_recon_errors_agg,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_on='date'\n",
    ").set_index('date')"
   ],
   "id": "b4de610c23a13d95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_val",
   "id": "e83df6501676d72a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below we compared three common thresholding methods to flag potential anomalies in LSTM-AE reconstruction scores:\n",
    "\n",
    "- **Mean + 2×Standard Deviation** (a classic statistical cut-off),\n",
    "- **95th percentile** (top 5% of scores),\n",
    "- **99th percentile** (very strict, top 1%).\n",
    "\n",
    "These methods are widely used in unsupervised time-series anomaly detection. Trinh (2022) and Kulkarni (2024) recommend percentile-based thresholds for their adaptability, while Bâra (2024) applies similar thresholds in hybrid weather anomaly pipelines. Wenig (2022) further supports this in a review of modern multivariate anomaly detection techniques."
   ],
   "id": "dc61f4c9d83f0fa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 10.4: Compute anomaly thresholds using three methods for lstm_score\n",
    "\n",
    "# Drop NA values in case some timestamps were unmatched during merge\n",
    "valid_lstm_scores = df_val['lstm_score'].dropna()\n",
    "\n",
    "# A. Mean + 2×Standard Deviation\n",
    "mean_lstm = valid_lstm_scores.mean()\n",
    "std_lstm = valid_lstm_scores.std()\n",
    "threshold_mean_2std = mean_lstm + 2 * std_lstm\n",
    "\n",
    "# B. 95th Percentile\n",
    "threshold_95 = valid_lstm_scores.quantile(0.95)\n",
    "\n",
    "# C. 99th Percentile\n",
    "threshold_99 = valid_lstm_scores.quantile(0.99)\n",
    "\n",
    "# Show thresholds\n",
    "print(\"Thresholds for LSTM-AE reconstruction error:\")\n",
    "print(f\"Mean + 2×Std: {threshold_mean_2std:.4f}\")\n",
    "print(f\"95th Percentile: {threshold_95:.4f}\")\n",
    "print(f\"99th Percentile: {threshold_99:.4f}\")"
   ],
   "id": "e483f3a36c1879c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(valid_lstm_scores, bins=100, kde=True, color='steelblue')\n",
    "plt.axvline(threshold_mean_2std, color='purple', linestyle='--', label='Mean + 2×Std')\n",
    "plt.axvline(threshold_95, color='orange', linestyle='--', label='95th Percentile')\n",
    "plt.axvline(threshold_99, color='red', linestyle='--', label='99th Percentile')\n",
    "plt.title(\"Distribution of LSTM-AE Reconstruction Errors with Thresholds (Validation Set)\")\n",
    "plt.xlabel(\"Mean Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "881f6128f116ba2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "total_scores = len(valid_lstm_scores)\n",
    "\n",
    "print(\"\\nAnomaly Count and Proportion by Threshold:\")\n",
    "for label, threshold in [\n",
    "    (\"Mean + 2×Std\", threshold_mean_2std),\n",
    "    (\"95th Percentile\", threshold_95),\n",
    "    (\"99th Percentile\", threshold_99)\n",
    "]:\n",
    "    count = (valid_lstm_scores > threshold).sum()\n",
    "    proportion = count / total_scores\n",
    "    print(f\"{label}: {count} anomalies ({proportion:.2%} of total)\")"
   ],
   "id": "896cc9228d166f1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Interpretation of the Histogram and Threshold Choice**\n",
    "\n",
    "The histogram shows a **slightly right-skewed** distribution of reconstruction errors. Most timestamps were reconstructed well by the LSTM Autoencoder, but a smaller number have higher errors — these lie in the long tail of the distribution.\n",
    "\n",
    "This pattern is expected, since the validation set includes **mostly normal sequences**, with a few contaminated by subtle anomalies that the model struggled to reconstruct.\n",
    "\n",
    "After comparing three common thresholding methods, we selected the **95th percentile** as our final cut-off for anomaly flagging. This threshold:\n",
    "\n",
    "- Adapts to the shape of the actual error distribution,\n",
    "- Captures **5% of the most abnormal timestamps**,\n",
    "- Is widely used in unsupervised time-series anomaly detection (Trinh, 2022; Kulkarni, 2024; Bâra, 2024),\n",
    "- Offers a practical balance — it's strict enough to highlight meaningful deviations without being too harsh or too lenient.\n",
    "\n",
    "In contrast, the **99th percentile** was too strict (only 1% flagged), and **Mean + 2×Std** flagged slightly fewer anomalies but lacked the adaptability of percentile-based methods.\n"
   ],
   "id": "c89d96b77d3ff1b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 10.6: Flag timestamps with unusually high reconstruction error\n",
    "\n",
    "# Reuse or recompute the threshold\n",
    "threshold_95 = df_val['lstm_score'].dropna().quantile(0.95)\n",
    "\n",
    "# Create a new boolean flag\n",
    "df_val['is_lstm_anomaly'] = (df_val['lstm_score'] > threshold_95).astype(float)\n",
    "\n",
    "# Optional: check how many were flagged\n",
    "n_anomalies = df_val['is_lstm_anomaly'].sum()\n",
    "print(f\"Timestamps flagged as LSTM anomalies: {n_anomalies}\")"
   ],
   "id": "ef2c196aae6d557d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 11: Hybrid Anomaly Labelling\n",
    "\n",
    "**Goal**: After evaluating the LSTM Autoencoder on filtered validation sequences, we now combine its anomaly flags with those from the Isolation Forest (IF) to assign final hybrid labels. This approach ensures that both **point anomalies** (detected by IF) and **pattern anomalies** (captured by LSTM-AE) are considered at each timestamp.\n",
    "\n",
    "Each timestamp is assigned one of the following labels:\n",
    "\n",
    "- **Normal**: not flagged by either model,\n",
    "- **Point anomaly**: flagged by IF only,\n",
    "- **Pattern anomaly**: flagged by LSTM-AE only,\n",
    "- **Compound anomaly**: flagged by both IF and LSTM-AE.\n",
    "\n",
    "This dual-labelling strategy is supported by Trinh (2022), Wenig (2022), and Kulkarni et al. (2024), who emphasise that combining statistical and temporal anomaly indicators enhances robustness in time-series anomaly detection. A similar hybrid pipeline is adopted by Bâra et al. (2024) in the context of extreme weather events.\n",
    "\n",
    "The hybrid labels will be used by:\n",
    "- the **XAI lead** to train and validate model-agnostic explanation techniques such as **TreeSHAP** and **Integrated Gradients**. Surrogate Random Forests remain an optional fallback.\n",
    "- the **dashboard lead** to visualise anomaly flags for end-users, with clear differentiation between point, pattern, and compound anomalies.\n",
    "\n",
    "This step consolidates complementary model outputs to enable richer interpretation, improved explainability, and actionable communication of weather anomalies."
   ],
   "id": "1d2abbc468584a57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 11.1: Assign hybrid anomaly labels based on IF and LSTM results\n",
    "\n",
    "def assign_label(row):\n",
    "    if row['is_if_anomaly'] and row['is_lstm_anomaly']:\n",
    "        return 'Compound anomaly'\n",
    "    elif row['is_if_anomaly']:\n",
    "        return 'Point anomaly'\n",
    "    elif row['is_lstm_anomaly']:\n",
    "        return 'Pattern anomaly'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "df_val.loc[:,'anomaly_label'] = df_val.apply(assign_label, axis=1)\n",
    "\n",
    "# drop rows where there no if score or lstm score\n",
    "df_val = df_val.dropna(subset=[\"if_score\",\"lstm_score\"])\n",
    "\n",
    "# Confirm there are no missing values in df_val\n",
    "print(f\"Are there any missing values in validation set? {'Yes' if df_val.isna().any().any() else 'No'}\")\n",
    "\n",
    "# Check the distribution of labels\n",
    "df_val['anomaly_label'].value_counts()"
   ],
   "id": "74392b314fee7375"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Retrospective Scoring and Labelling Strategy\n",
    "\n",
    "Following the validation stage in Step 10, where the LSTM Autoencoder demonstrated consistent behaviour on clean, unseen data, we now apply it retrospectively to the full training set. This decision is based on its observed ability to generalise, as reflected in the validation results.\n",
    "\n",
    "In **Step 12**, the trained LSTM-AE is applied to all available training timestamps **without anomaly filtering**, allowing us to score the complete historical record and flag potential pattern anomalies. This simulates inference-time conditions and supports the generation of pseudo-labels in the absence of ground truth.\n",
    "\n",
    "For the Isolation Forest, no additional scoring is required — it was applied to the entire dataset from the outset. However, in **Step 13**, we apply a **relaxed 3rd percentile threshold** (distinct from the stricter training mask) to simulate how IF would behave in real-time deployment.\n",
    "\n",
    "This retrospective evaluation approach is widely supported in the literature as a standard practice for unsupervised anomaly detection when ground truth labels are unavailable. Trinh (2022), Darban (2024), Antwarg et al. (2021), and Wenig (2022) all recommend applying trained models to full datasets using inference-mode thresholds for downstream labelling and analysis."
   ],
   "id": "4d95167ef82c28f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 12 – Retrospective LSTM-AE Scoring on Training Set\n",
    "\n",
    "**Goal**: Evaluate the trained LSTM Autoencoder on the full training set using 720-hour sliding windows. Unlike Step 5 (which only used clean windows for training), this step includes **all possible sequences**, regardless of anomaly presence.\n",
    "\n",
    "For each sequence:\n",
    "- The model reconstructs the 8 raw + time features.\n",
    "- Reconstruction errors are computed per hour (MAE).\n",
    "- These are flattened across overlapping windows and **aggregated by timestamp** using the mean.\n",
    "\n",
    "This allows us to:\n",
    "- Detect **pattern anomalies** in the historical training data,\n",
    "- Flag new anomalies using a 95th percentile threshold on MAE,\n",
    "- Compare LSTM-AE behaviour across **seen** vs **unseen** data (`used_in_lstm_training`),\n",
    "- Generate a new column `anomaly_label = is_if_anomaly | is_lstm_anomaly` for hybrid analysis and dashboard support.\n",
    "\n",
    "This step mirrors Step 5.3, but applies to the training set without any sequence-level masking."
   ],
   "id": "2cb377ffe2603076"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a copy of df_train to differentiate between the training set and retrospective test set based on df_train\n",
    "df_train_infer = df_train.copy()\n",
    "df_train_infer = df_train_infer.dropna(subset=if_features)"
   ],
   "id": "8d89c36d73ed7a79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.1 – Construct all 720-hour sequences from df_train_infer for retrospective scoring (with robust scaling)\n",
    "\n",
    "# For retrospective scoring, we accept *all* sequences regardless of anomalies\n",
    "max_anomalies_infer = sequence_length  # i.e. disable filtering\n",
    "\n",
    "seq_inputs_train, seq_start_times_train, test_debug = construct_lstm_sequences(\n",
    "    df_train_infer,\n",
    "    sequence_length=sequence_length,\n",
    "    sequence_stride=sequence_stride,\n",
    "    max_allowed_anomalies=max_anomalies_infer,\n",
    "    lstm_input_cols_all=lstm_input_cols_all,\n",
    "    feature_indices=feature_indices,\n",
    "    desc_label=\"Retrospective Scoring\"\n",
    ")\n",
    "\n",
    "print(\"Step 12.1 complete – all sequences extracted and robustly scaled.\")\n",
    "print(f\"Window stats: {test_debug}\")"
   ],
   "id": "fc8d011125509fea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.2 – Predict reconstructions using trained LSTM-AE\n",
    "\n",
    "# Stack sequences into a 3D NumPy array\n",
    "X_seq_train = np.stack(seq_inputs_train)\n",
    "\n",
    "# Predict reconstructions\n",
    "recon_seq_train = autoencoder.predict(X_seq_train, verbose=1)\n",
    "\n",
    "# Compute MAE per timestep in each sequence\n",
    "mae_seq_train = np.mean(np.abs(X_seq_train - recon_seq_train), axis=2)"
   ],
   "id": "a28b8da469a3f92d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.3 – Efficiently flatten reconstruction errors to timestamp-level DataFrame\n",
    "\n",
    "# Ensure start_times_np is a proper NumPy datetime64 array\n",
    "start_times_np = np.array(pd.to_datetime(seq_start_times_train))  # Now it's shape (n_sequences,)\n",
    "\n",
    "# Build 2D timestamp array: shape (n_sequences, sequence_length)\n",
    "timestamps_array = start_times_np[:, None] + np.arange(sequence_length).astype(\"timedelta64[h]\")\n",
    "\n",
    "# Flatten both arrays\n",
    "flat_timestamps = timestamps_array.ravel()\n",
    "flat_errors = mae_seq_train.ravel()\n",
    "\n",
    "# Assemble tidy DataFrame\n",
    "df_lstm_errors_train = pd.DataFrame({\n",
    "    \"date\": flat_timestamps,\n",
    "    \"lstm_score\": flat_errors\n",
    "}).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Step 12.3 complete – Flattened {len(df_lstm_errors_train)} timestamp-level scores.\")"
   ],
   "id": "20b3135f24fcaa18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.4 – Aggregate MAE per timestamp\n",
    "\n",
    "# Some timestamps appear in multiple overlapping sequences — we average their MAEs\n",
    "df_lstm_errors_train_agg = (\n",
    "    df_lstm_errors_train\n",
    "    .groupby(\"date\")[\"lstm_score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Clean old score if it exists\n",
    "df_train_infer = df_train_infer.drop(columns=\"lstm_score\", errors=\"ignore\")\n",
    "\n",
    "# Merge lstm_score into df_train_infer\n",
    "df_train_infer = df_train_infer.merge(\n",
    "    df_lstm_errors_train_agg,\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_on=\"date\"\n",
    ").set_index(\"date\")\n",
    "\n",
    "print(f\"Merged LSTM scores for {df_lstm_errors_train_agg.shape[0]} unique timestamps.\")\n",
    "print(f\"Proportion of df_train_infer with LSTM scores: {(~df_train_infer['lstm_score'].isna()).mean():.2%}\")"
   ],
   "id": "91568d375e1eba41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_train_infer[\"lstm_score\"].describe()",
   "id": "297ef5af86b26bd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Interpretation of Key Stats for LSTM scores in Training Set**\n",
    "\n",
    "The LSTM-AE reconstruction scores in the training set show a normal and stable pattern overall. Most values fall between 0.37 and 0.50, with a few spikes above 1.0, which are likely linked to rare and complex anomalies. The average score of 0.44 is close to 0.40 seen on the compartively clean validation sequences, suggesting that the model performs consistently even across unfiltered data."
   ],
   "id": "708a5b537bc1519f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.5 – Flag LSTM anomalies using 95th percentile threshold\n",
    "\n",
    "# Calculate threshold based on training reconstruction errors\n",
    "lstm_threshold_train = df_train_infer[\"lstm_score\"].dropna().quantile(0.95)\n",
    "df_train_infer[\"is_lstm_anomaly\"] = (df_train_infer[\"lstm_score\"] > lstm_threshold_train).astype(float)\n",
    "\n",
    "print(f\"LSTM anomaly threshold (95th percentile): {lstm_threshold_train:.4f}\")\n",
    "print(f\"Flagged anomalies: {df_train_infer['is_lstm_anomaly'].sum():.0f} \"\n",
    "      f\"({(df_train_infer['is_lstm_anomaly'].mean() * 100):.2f}%)\")"
   ],
   "id": "3aeeba47ab7cec11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.6 – Visualise LSTM score distribution with anomaly threshold (Training Set)\n",
    "\n",
    "# Extract scores and threshold\n",
    "train_lstm_scores = df_train_infer[\"lstm_score\"]\n",
    "threshold = lstm_threshold_train  # already computed in Step 12.5\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train_lstm_scores, bins=100, kde=True, color='steelblue')\n",
    "plt.axvline(threshold, color='orange', linestyle='--', label='95th Percentile')\n",
    "\n",
    "plt.title(\"Distribution of LSTM-AE Reconstruction Errors with Thresholds (Retrospective Test Set)\")\n",
    "plt.xlabel(\"Mean Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "df32d11e1c54c7fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.6 – Assign pseudo-label (based on IF or LSTM anomaly)\n",
    "\n",
    "# Assign label\n",
    "df_train_infer[\"anomaly_label\"] = df_train_infer.apply(assign_label, axis=1)\n",
    "\n",
    "# Optional binary pseudo-label for downstream tasks\n",
    "# df_train_infer[\"pseudo_label\"] = (df_train_infer[\"anomaly_label\"] != \"Normal\").astype(int) # keep for future work\n",
    "\n",
    "# Final log\n",
    "print(f\"Anomalies flagged only by LSTM-AE (95th Percentile): {len(df_train_infer[df_train_infer['anomaly_label'] =='Pattern anomaly'])}\")\n",
    "print(f\"Anomalies flagged only by IF (3rd percentile): {len(df_train_infer[df_train_infer['anomaly_label']=='Point anomaly'])}\")\n",
    "print(f\"Anomalies flagged by both LSTM-AE (95th Percentile) and IF (3rd percentile): {len(df_train_infer[df_train_infer['anomaly_label']=='Compound anomaly'])}\")\n",
    "print(f\"Pseudo-labelled anomalies: {len(df_train_infer[df_train_infer['anomaly_label']!='Normal'])} / {len(df_train_infer)}\")\n",
    "print(f\"Anomalous timestamps vs Total Timestamps: {len(df_train_infer[df_train_infer['anomaly_label']!='Normal'])/len(df_train_infer):.2%}\")"
   ],
   "id": "b2187249afdde9e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1 – Get value counts and percentages\n",
    "counts = df_train_infer[\"anomaly_label\"].value_counts()\n",
    "percentages = df_train_infer[\"anomaly_label\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# Step 2 – Combine into a DataFrame\n",
    "summary = pd.DataFrame({\"Count\": counts, \"Percentage\": percentages.round(2)}).reset_index()\n",
    "summary.columns = [\"Anomaly Type\", \"Count\", \"Percentage\"]\n",
    "\n",
    "# Step 3 – Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(summary[\"Anomaly Type\"], summary[\"Count\"], color=\"steelblue\")\n",
    "\n",
    "# Add % labels above bars\n",
    "for bar, pct in zip(bars, summary[\"Percentage\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 100, f\"{pct:.1f}%\",\n",
    "            ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "# Final plot formatting\n",
    "ax.set_title(\"Anomaly Type Distribution (Training Set)\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Anomaly Type\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "bf168c5a72b10852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Hybrid Anomaly Labelling Summary (Retrospective – Training Set)**\n",
    "\n",
    "After applying both the LSTM Autoencoder and Isolation Forest to the full training set, anomalies were pseudo-labelled as follows:\n",
    "\n",
    "- **Pattern anomalies** (flagged only by LSTM-AE @ 95th percentile): 2,853 timestamps (4.11%)\n",
    "- **Point anomalies** (flagged only by IF @ 3rd percentile): 1,465 timestamps (2.11%)\n",
    "- **Compound anomalies** (flagged by both models): 618 timestamps (0.89%)\n",
    "- **Total pseudo-labelled anomalies**: 4,936 of 69,409 timestamps (**7.11%**)\n",
    "\n",
    "This distribution reflects best practice in hybrid anomaly detection:\n",
    "\n",
    "- Deep models like LSTM-AE often highlight **pattern-based anomalies** across long sequences (Trinh, 2022; Kulkarni, 2024).\n",
    "- **Compound anomalies** — caught by both models — are typically more severe or high-confidence (Bâra, 2024).\n",
    "- A **7.11% total anomaly rate** aligns with real-world expectations; Wenig (2022) notes that 5–10% is typical for unsupervised anomaly detection.\n",
    "- Combining models increases detection coverage and reduces blind spots, as each captures different anomaly types (Antwarg et al., 2021).\n",
    "\n",
    "These hybrid labels lay the groundwork for explainability and user-facing insights in the dashboard module."
   ],
   "id": "690f05109e25bf06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.7 – Diagnostic: Mean LSTM-AE MAE by anomaly type and training exposure\n",
    "\n",
    "# Group and unstack\n",
    "agg_df = (\n",
    "    df_train_infer\n",
    "    .groupby([\"anomaly_label\", \"used_in_lstm_training\"])[\"lstm_score\"]\n",
    "    .mean()\n",
    "    .unstack(fill_value=np.nan)\n",
    ")\n",
    "\n",
    "# Optional: rename columns (safer if both True/False exist)\n",
    "if True in agg_df.columns and False in agg_df.columns:\n",
    "    agg_df = agg_df.rename(columns={False: \"Unseen (False)\", True: \"Seen (True)\"})\n",
    "    agg_df[\"Difference\"] = agg_df[\"Unseen (False)\"] - agg_df[\"Seen (True)\"]\n",
    "else:\n",
    "    print(\"Warning: One of the exposure types (True or False) is missing in data.\")\n",
    "\n",
    "# Ensure row order if labels are all present\n",
    "expected_labels = [\"Normal\", \"Point anomaly\", \"Pattern anomaly\", \"Compound anomaly\"]\n",
    "agg_df = agg_df.reindex([lbl for lbl in expected_labels if lbl in agg_df.index])\n",
    "\n",
    "agg_df"
   ],
   "id": "95a95c852e1b556"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**LSTM-AE Diagnostic Summary: Seen vs Unseen Timestamps (Training Set)**\n",
    "\n",
    "We compared the LSTM Autoencoder’s reconstruction error (MAE) across different anomaly types, distinguishing between timestamps used during training and those it had never seen.\n",
    "\n",
    "- **Normal timestamps** had very similar errors:\n",
    "  - Seen: **0.406** vs. Unseen: **0.433** → Δ = 0.027\n",
    "  This confirms strong generalisation on typical patterns (Trinh, 2022).\n",
    "\n",
    "- **Point anomalies** had slightly higher errors on unseen data:\n",
    "  - Seen: **0.438** vs. Unseen: **0.478** → Δ = 0.040\n",
    "  A modest gap, as expected for irregular but localised deviations (Darban, 2024).\n",
    "\n",
    "- **Pattern anomalies** showed only a small difference:\n",
    "  - Seen: **0.705** vs. Unseen: **0.715** → Δ = 0.010\n",
    "  Suggests that the model can handle mild temporal deviations robustly.\n",
    "\n",
    "- **Compound anomalies** had the largest gap:\n",
    "  - Seen: **0.709** vs. Unseen: **0.796** → Δ = 0.087\n",
    "  These rare and complex cases are hardest to reconstruct when unfamiliar (Bâra, 2024; Wenig, 2022).\n",
    "\n",
    "Overall, reconstruction error increases with anomaly complexity and novelty, confirming that the LSTM-AE behaves as expected in a hybrid anomaly detection setting.\n",
    "\n",
    "---\n",
    "\n",
    "**Inference Threshold Justification for LSTM-AE Anomaly Scoring**\n",
    "\n",
    "For this MVP, we derive the inference LSTM-AE anomaly threshold by applying the trained model to the entire training set (`df_train_infer`) and selecting the 95th percentile of per-timestamp MAE scores. This strategy is both practical and supported by the data:\n",
    "\n",
    "- The LSTM-AE was trained only on clean sequences, yet generalises well to unseen parts of the training set. Mean reconstruction error on normal (non-anomalous) sequences rose only marginally from 0.406 to 0.433 (+6.6%), indicating stable behaviour across the dataset.\n",
    "- Errors for anomalies (especially compound and point anomalies) remain significantly higher than those for normal data, even in unseen regions. This confirms the model's ability to flag abnormal patterns reliably.\n",
    "\n",
    "This approach allows us to set a **realistic and conservative threshold** based on the largest available, temporally diverse dataset. It also avoids the risks of data leakage or overfitting to the short validation subset.\n",
    "\n",
    "In a future production-grade system, this process could be improved by:\n",
    "- Withholding a dedicated normal-only test period (e.g. 6–12 months of untrained historical data) to simulate inference and derive thresholds more robustly,\n",
    "- Re-evaluating the threshold periodically to monitor for drift or seasonal regime shifts.\n",
    "\n",
    "This thresholding practice aligns with anomaly detection guidelines in Trinh (2022) and Darban (2024), where unsupervised error distributions are used to flag deviations without labelled outcomes."
   ],
   "id": "a7611c1d2927f3dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 12.8: Violin plots of LSTM-AE error across all anomaly labels (training set)\n",
    "\n",
    "# Prepare data\n",
    "df_plot = df_train_infer[[\"anomaly_label\", \"lstm_score\"]].dropna()\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# Create violin plot with hue assigned\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(\n",
    "    x=\"anomaly_label\",\n",
    "    y=\"lstm_score\",\n",
    "    hue=\"anomaly_label\",\n",
    "    data=df_plot,\n",
    "    inner=\"box\",\n",
    "    palette=\"muted\",\n",
    "    legend=False,\n",
    "    cut=0\n",
    ")\n",
    "\n",
    "# Clean visuals\n",
    "plt.title(\"Distribution of LSTM-AE Reconstruction Error by Anomaly Type\", fontsize=14)\n",
    "plt.xlabel(\"Anomaly Type\", fontsize=12)\n",
    "plt.ylabel(\"LSTM-AE Score (MAE)\", fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b5bee0947d384a88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Visual Check: LSTM-AE Reconstruction Error by Anomaly Type**\n",
    "\n",
    "The violin plot shows how LSTM-AE reconstruction error (MAE) varies across different types of anomalies:\n",
    "\n",
    "- **Normal** timestamps have the lowest and tightest error scores, showing the model reconstructs familiar patterns well (Trinh, 2022).\n",
    "- **Point anomalies** show slightly higher errors, but the model still handles them reasonably, as they often affect only short-term behaviour (Darban, 2024).\n",
    "- **Pattern anomalies** have a sharp upward shift, indicating that the LSTM-AE struggles with less familiar or structurally complex sequences (Wenig, 2022).\n",
    "- **Compound anomalies** have the highest and most spread-out errors, confirming these are the most difficult cases for the model to reconstruct (Antwarg et al., 2021; Bâra, 2024).\n",
    "\n",
    "This pattern matches published findings and confirms that reconstruction error can reliably indicate anomaly type and severity."
   ],
   "id": "d05052a821e7760e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Step 13: Empirical Test of Hybrid Anomaly Detection System (Feb 2020)",
   "id": "d9fbbef906a67da7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Step 13.1 – Visualise IF, LSTM-AE, and Compound Anomalies for February 2020\n",
    "\n",
    "# Filter to February 2020\n",
    "df_feb2020 = df_train_infer.loc[\"2020-02-01\":\"2020-02-29\"]\n",
    "\n",
    "# Define anomaly subgroups\n",
    "if_anoms = df_feb2020[df_feb2020[\"anomaly_label\"] == \"Point anomaly\"].index\n",
    "lstm_anoms = df_feb2020[df_feb2020[\"anomaly_label\"] == \"Pattern anomaly\"].index\n",
    "compound_anoms = df_feb2020[df_feb2020[\"anomaly_label\"] == \"Compound anomaly\"].index\n",
    "\n",
    "# Features to plot (assumes 'raw_features' exists and includes 3 variables)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(raw_features), ncols=1,\n",
    "    figsize=(14, 9),\n",
    "    sharex=True,\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "# Colour settings\n",
    "colours = {\n",
    "    \"IF\": \"red\",\n",
    "    \"LSTM\": \"orange\",\n",
    "    \"Compound\": \"purple\"\n",
    "}\n",
    "\n",
    "# Plot features with anomaly overlays\n",
    "for i, feature in enumerate(raw_features):\n",
    "    ax = axes[i]\n",
    "    ax.plot(df_feb2020.index, df_feb2020[feature], label=feature, color='tab:blue')\n",
    "\n",
    "    # Overlay anomaly lines by type\n",
    "    for ts in if_anoms:\n",
    "        ax.axvline(ts, color=colours[\"IF\"], linestyle='dotted', linewidth=0.9, alpha=0.5)\n",
    "    for ts in lstm_anoms:\n",
    "        ax.axvline(ts, color=colours[\"LSTM\"], linestyle='dotted', linewidth=0.9, alpha=0.5)\n",
    "    for ts in compound_anoms:\n",
    "        ax.axvline(ts, color=colours[\"Compound\"], linestyle='dotted', linewidth=0.9, alpha=0.6)\n",
    "\n",
    "    ax.set_ylabel(feature)\n",
    "\n",
    "# Define custom legend handles for anomaly types\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=colours[\"IF\"], linestyle='dotted', linewidth=1.5, label='Point anomaly (IF)'),\n",
    "    Line2D([0], [0], color=colours[\"LSTM\"], linestyle='dotted', linewidth=1.5, label='Pattern anomaly (LSTM-AE)'),\n",
    "    Line2D([0], [0], color=colours[\"Compound\"], linestyle='dotted', linewidth=1.5, label='Compound anomaly')\n",
    "]\n",
    "\n",
    "# Add the custom legend to just one axis (e.g. the last one)\n",
    "axes[-1].legend(handles=legend_elements, loc='lower right', title='Anomaly Types')\n",
    "\n",
    "# Label x-axis and add title\n",
    "axes[-1].set_xlabel(\"Timestamp (February 2020)\")\n",
    "fig.suptitle(\"Raw Weather Features with Anomaly Markers – February 2020\", fontsize=14)\n",
    "\n",
    "# Rotate x-axis tick labels\n",
    "for ax in axes:\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(35)\n",
    "        label.set_ha('right')\n",
    "\n",
    "plt.show()"
   ],
   "id": "4b9e5d62532122f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    # Step 13.2: Quantitative Summary of Anomalies – February 2020\n",
    "\n",
    "# Define core weather features and label order\n",
    "features = [\"temperature_2m\", \"surface_pressure\", \"wind_speed_10m\", \"precipitation\"]\n",
    "label_order = [\"Normal\", \"Point anomaly\", \"Pattern anomaly\", \"Compound anomaly\"]\n",
    "\n",
    "# Compute mean values by anomaly label\n",
    "mean_by_label = df_feb2020.groupby(\"anomaly_label\")[features].mean()\n",
    "\n",
    "# Compute delta from \"Normal\" for each anomaly type\n",
    "delta_from_normal = mean_by_label.subtract(mean_by_label.loc[\"Normal\"])\n",
    "\n",
    "# Round for readability\n",
    "mean_rounded = mean_by_label.round(2).reindex(label_order)\n",
    "delta_rounded = delta_from_normal.round(2).reindex(label_order)\n",
    "\n",
    "# Combine for display\n",
    "summary_df = mean_rounded.join(delta_rounded, rsuffix=\" Δ\")\n",
    "display(summary_df)"
   ],
   "id": "51ac9ea651256091"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Expected feature and label setup\n",
    "features = [\"temperature_2m\", \"surface_pressure\", \"wind_speed_10m\", \"precipitation\"]\n",
    "label_order = [\"Normal\", \"Point anomaly\", \"Pattern anomaly\", \"Compound anomaly\"]\n",
    "\n",
    "# Compute mean values by anomaly label\n",
    "mean_by_label = df_feb2020.groupby(\"anomaly_label\")[features].mean()\n",
    "\n",
    "# Compute delta from \"Normal\" group\n",
    "delta_from_normal = mean_by_label.subtract(mean_by_label.loc[\"Normal\"])\n",
    "\n",
    "# Round for readability\n",
    "mean_rounded = mean_by_label.round(2).reindex(label_order)\n",
    "delta_rounded = delta_from_normal.round(2).reindex(label_order)\n",
    "\n",
    "# Compute absolute delta from \"Normal\" group\n",
    "abs_delta_from_normal = delta_from_normal.abs().round(2).reindex(label_order)\n",
    "\n",
    "# Compute standard deviation per anomaly label\n",
    "std_by_label = df_feb2020.groupby(\"anomaly_label\")[features].std().round(2).reindex(label_order)\n",
    "\n",
    "# Combine all into one extended summary\n",
    "extended_summary_df = (\n",
    "    mean_rounded\n",
    "    .add_suffix(\" (Mean)\")\n",
    "    .join(abs_delta_from_normal.add_suffix(\" (|Δ|)\"))\n",
    "    .join(std_by_label.add_suffix(\" (Std Dev)\"))\n",
    ")\n",
    "\n",
    "extended_summary_df"
   ],
   "id": "85977d3d3ee00f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Anomaly Summary – February 2020 (Weather Feature Insights)**\n",
    "\n",
    "**What Worked Well**\n",
    "\n",
    "We tested the hybrid anomaly detection system on **February 2020**, a month with major storms (Ciara and Dennis). The model successfully flagged key weather events:\n",
    "\n",
    "- **Compound anomalies** (flagged by both IF and LSTM-AE) matched peak storm conditions:\n",
    "  - Wind speeds over **40 km/h**\n",
    "  - Pressure below **990 hPa**\n",
    "  - Rainfall above **1.7 mm/h**\n",
    "  - Temperature deviating by more than **4.2°C**\n",
    "\n",
    "  > These align with known patterns for UK winter storms (Wenig, 2022; Bâra, 2024).\n",
    "\n",
    "- **Pattern anomalies** picked up broader shifts like falling pressure and wind surges.\n",
    "- **Point anomalies** captured quick bursts in rainfall.\n",
    "\n",
    "**What Could Be Improved**\n",
    "\n",
    "Some rainfall spikes and freezing temperatures were missed. Likely reasons:\n",
    "\n",
    "- `precip_log` was **not scaled** for the LSTM-AE because of its skew and sparsity. Standard or robust scaling made it less effective (Trinh, 2022).\n",
    "- In MAE loss, all features are treated equally. Despite robust scaling, **wind has a larger numeric range**, so it can still dominate the loss (Antwarg, 2021; Tawalkuli, 2024).\n",
    "\n",
    "  > Wind was **smoothed and robust-scaled for IF**, but **not smoothed** for LSTM-AE.\n",
    "  > Precipitation was **log-transformed and z-scored for IF**, but left raw for LSTM-AE.\n",
    "\n",
    "**How Much Each Feature Deviated (vs Normal)**\n",
    "\n",
    "All differences are shown in **absolute terms**:\n",
    "\n",
    "| Anomaly Type      | Temp (°C) | Wind (km/h) | Pressure (hPa) | Rain (mm/h) |\n",
    "|------------------|-----------|-------------|----------------|-------------|\n",
    "| Point anomaly     | 0.35      | 2.18        | 3.23           | 0.54        |\n",
    "| Pattern anomaly   | 1.34      | 8.71        | 5.05           | 0.16        |\n",
    "| Compound anomaly  | 4.17      | 18.45       | 19.23          | 1.60        |\n",
    "\n",
    "Compound anomalies showed the **largest combined shifts**, particularly in pressure and wind. Pattern anomalies reflected structural changes, and point anomalies mostly highlighted rain spikes.\n",
    "\n",
    "**Overall Verdict (MVP scope)**\n",
    "\n",
    "- The hybrid model flagged high-impact events clearly.\n",
    "- Anomalies were distinct and interpretable.\n",
    "- Labels are suitable for **XAI and dashboard visualisation**.\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "- Test **feature re-weighting** in the loss to balance rainfall and temperature (Antwarg, 2021).\n",
    "- Consider **rain-specific flags** (e.g. >4 mm/h) for extreme bursts (Trinh, 2022).\n",
    "- Add **post-hoc rules** for sub-zero temperatures or compound triggers (Liu, 2020; Bâra, 2024).\n"
   ],
   "id": "7c7f030dd5dabaf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 14 – Save Inference Outputs and Artefacts\n",
    "\n",
    "**Goal**:\n",
    "Store key post-inference artefacts required for explainability, dashboard integration, and reproducibility. These include the fully labelled `df_train_infer`, LSTM input sequences, aligned timestamps, and model threshold values. This ensures the XAI layer, operational dashboard team, and future retraining efforts can all access consistent and versioned outputs.\n",
    "\n",
    "**Outputs Saved**:\n",
    "- `df_train_infer.csv` – enriched scoring dataset with all features, scores, and labels\n",
    "- `X_train_infer_sequences.npy` – 3D array of LSTM input sequences\n",
    "- `seq_start_times_train.npy` – timestamps corresponding to LSTM sequences\n",
    "- `inference_thresholds.txt` – final thresholds used for IF and LSTM anomaly flagging"
   ],
   "id": "fc848dea9e5465b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 14.1 – Save df_train_infer\n",
    "# This dataset contains raw and transformed features, anomaly scores, flags, and labels\n",
    "\n",
    "# Get current timestamp in desired format, e.g., 20240605_1130\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "df_train_infer.to_csv(f\"{MODEL_PREDICTIONS_DIR}df_train_infer_{current_time}.csv\")\n",
    "print(\"Saved df_train_infer to outputs/modelling/predictions/\")"
   ],
   "id": "7d2f6b4a1be689f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 14.2 – Save LSTM Inference Sequences and Timestamps\n",
    "\n",
    "# Get current timestamp in desired format, e.g., 20240605_1130\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "np.save(f\"{MODEL_INPUT_DIR}X_train_infer_sequences_{current_time}.npy\", X_seq_train)\n",
    "np.save(f\"{MODEL_INPUT_DIR}seq_start_times_train_{current_time}.npy\", np.array(seq_start_times_train))\n",
    "print(\"Saved LSTM sequences and timestamps to data/processed/model_input/\")"
   ],
   "id": "f04a66bed324c838"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Step 14.3 – Save Inference Metadata (Thresholds + Feature Lists) ===\n",
    "\n",
    "# Get current timestamp in desired format, e.g., 20240605_1130\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "with open(f\"{MODEL_METADATA_DIR}inference_metadata_{current_time}.txt\", \"w\") as f:\n",
    "    # Thresholds\n",
    "    f.write(f\"IF threshold (3rd percentile): {if_threshold_train:.5f}\\n\")\n",
    "    f.write(f\"IF threshold (1st percentile): {if_threshold_val:.5f}\\n\")\n",
    "    f.write(f\"LSTM threshold (95th percentile): {lstm_threshold_train:.5f}\\n\\n\")\n",
    "\n",
    "    # IF feature list\n",
    "    f.write(\"IF model input features:\\n\")\n",
    "    f.write(\", \".join(if_features) + \"\\n\\n\")\n",
    "\n",
    "    # LSTM-AE feature list\n",
    "    f.write(\"LSTM-AE input features - all robust-scaled per sequence except `precip_log`:\\n\")\n",
    "    f.write(\", \".join(lstm_features) + \"\\n\\n\")\n",
    "\n",
    "    # LSTM-AE time features\n",
    "    f.write(\"LSTM-AE time features - left in raw form:\\n\")\n",
    "    f.write(\", \".join(lstm_time_features) + \"\\n\")\n",
    "\n",
    "print(f\"Saved full inference metadata to {MODEL_METADATA_DIR}inference_metadata_{current_time}.txt\")"
   ],
   "id": "70fef954432b37a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca5d0432d72eef93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
