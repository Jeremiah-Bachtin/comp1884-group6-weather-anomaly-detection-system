{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing & Modelling Pipeline",
   "id": "3c1b69603cea15be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:57:05.206317Z",
     "start_time": "2025-05-18T12:57:05.180659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import joblib\n",
    "from utils.find_root import find_project_root"
   ],
   "id": "2d2d5f1a37782522",
   "outputs": [],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:20:46.543719Z",
     "start_time": "2025-05-18T12:20:46.528757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve the project root dynamically\n",
    "project_root = find_project_root()\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Define output directories for ML models\n",
    "MODEL_OUTPUT_DIR = \"outputs/modelling/models/\"\n",
    "MODEL_INPIT_OUTPUT_DIR = \"data/processed/model_input\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_INPIT_OUTPUT_DIR, exist_ok=True)"
   ],
   "id": "95d7b0549f2bae68",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Step 0 - Dataset Loading and Splitting",
   "id": "37fd4474402b8c7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:07:21.326735Z",
     "start_time": "2025-05-18T08:07:21.232640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 0.1 Load dataset\n",
    "DATASET_PATH = \"data/processed/historical_merged/historical_IFS_merged_201702_to_202504.csv\"\n",
    "df = pd.read_csv(DATASET_PATH, parse_dates=['date'], index_col='date')\n",
    "df = df.asfreq('h')\n",
    "df"
   ],
   "id": "6fcfeb9dce058167",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     temperature_2m  surface_pressure  precipitation  \\\n",
       "date                                                                   \n",
       "2017-02-01 00:00:00             9.6            1008.2            0.0   \n",
       "2017-02-01 01:00:00             9.6            1007.4            0.0   \n",
       "2017-02-01 02:00:00             9.9            1006.8            0.6   \n",
       "2017-02-01 03:00:00            10.0            1006.5            0.3   \n",
       "2017-02-01 04:00:00            10.2            1006.2            0.3   \n",
       "...                             ...               ...            ...   \n",
       "2025-04-30 19:00:00            25.1            1016.6            0.0   \n",
       "2025-04-30 20:00:00            23.0            1016.8            0.0   \n",
       "2025-04-30 21:00:00            20.7            1017.3            0.0   \n",
       "2025-04-30 22:00:00            19.2            1017.5            0.0   \n",
       "2025-04-30 23:00:00            18.0            1017.5            0.0   \n",
       "\n",
       "                     wind_speed_10m  \n",
       "date                                 \n",
       "2017-02-01 00:00:00            14.6  \n",
       "2017-02-01 01:00:00            14.6  \n",
       "2017-02-01 02:00:00            15.1  \n",
       "2017-02-01 03:00:00            15.0  \n",
       "2017-02-01 04:00:00            15.5  \n",
       "...                             ...  \n",
       "2025-04-30 19:00:00            10.1  \n",
       "2025-04-30 20:00:00            11.9  \n",
       "2025-04-30 21:00:00            11.9  \n",
       "2025-04-30 22:00:00             9.0  \n",
       "2025-04-30 23:00:00             7.0  \n",
       "\n",
       "[72264 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-02-01 00:00:00</th>\n",
       "      <td>9.6</td>\n",
       "      <td>1008.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01 01:00:00</th>\n",
       "      <td>9.6</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01 02:00:00</th>\n",
       "      <td>9.9</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01 03:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1006.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01 04:00:00</th>\n",
       "      <td>10.2</td>\n",
       "      <td>1006.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30 19:00:00</th>\n",
       "      <td>25.1</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30 20:00:00</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30 21:00:00</th>\n",
       "      <td>20.7</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30 22:00:00</th>\n",
       "      <td>19.2</td>\n",
       "      <td>1017.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30 23:00:00</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1017.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72264 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:07:22.599445Z",
     "start_time": "2025-05-18T08:07:22.586442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 0.2: Define chronological splits\n",
    "train_start, train_end = \"2017-02-01\", \"2025-01-31\"\n",
    "val_start, val_end = \"2025-02-01\", \"2025-04-30\"\n",
    "\n",
    "# Step 0.3: Subset dataframe\n",
    "df_train = df.loc[train_start:train_end]\n",
    "df_val = df.loc[val_start:val_end]\n",
    "\n",
    "print(f\"Training set: {len(df_train)} rows (~{len(df_train)/24:.0f} days).\")\n",
    "print(f\"Validation set: {len(df_val)} rows (~{len(df_val)/24:.0f}days).\")"
   ],
   "id": "d4ef090c236c9dd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 70128 rows (~2922 days).\n",
      "Validation set: 2136 rows (~89days).\n"
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 1 – Feature Transformation & Normalisation\n",
    "**Goal**: Transform raw weather variables into scale-stable, model-ready features using rolling statistics. This includes z-scores, IQR scaling, smoothing, and log transforms. These steps are applied before training the Isolation Forest and LSTM-AE models to ensure consistency across training, validation, and inference."
   ],
   "id": "9217db6f238464e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:44.139948Z",
     "start_time": "2025-05-18T08:08:44.126201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.1: Select features (precautionary)\n",
    "features = ['temperature_2m', 'surface_pressure', 'wind_speed_10m', 'precipitation']\n",
    "df_train = df_train[features].copy()\n",
    "df_val =df_val[features].copy()"
   ],
   "id": "ade595eb4dc49513",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:44.960131Z",
     "start_time": "2025-05-18T08:08:44.955134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.2: Set parameters for normalisation\n",
    "window_60d = 1440 # rolling window size\n",
    "min_periods_60d = 720 # minimum number of observations required for rolling calculations\n",
    "window_12h = 12 # rolling window size for 12-hour rolling z-score\n",
    "min_periods_12h = 6 # minimum number of observations required for rolling calculations for 12-hour rolling z-score\n",
    "eps = 1e-6  # to avoid division by zero in rolling scaling calculations for precipitation and wind"
   ],
   "id": "1f7a6f38d6f15627",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:45.426603Z",
     "start_time": "2025-05-18T08:08:45.409273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.3 Temperature and Surface Pressure: 60-day rolling z-scores\n",
    "for col in ['temperature_2m', 'surface_pressure']:\n",
    "    # Train set\n",
    "    mean_train = df_train[col].rolling(window=window_60d, min_periods=min_periods_60d).mean()\n",
    "    std_train = df_train[col].rolling(window=window_60d, min_periods=min_periods_60d).std()\n",
    "    df_train[f'{col}_z'] = (df_train[col] - mean_train) / (std_train + eps)\n",
    "\n",
    "    # Validation set\n",
    "    mean_val = df_val[col].rolling(window=window_60d, min_periods=min_periods_60d).mean()\n",
    "    std_val = df_val[col].rolling(window=window_60d, min_periods=min_periods_60d).std()\n",
    "    df_val[f'{col}_z'] = (df_val[col] - mean_val) / (std_val + eps)"
   ],
   "id": "e94eb3511e6c0e4d",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:45.909702Z",
     "start_time": "2025-05-18T08:08:45.899950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.4: Apply smoothing to wind speed (NO Z-SCORE)\n",
    "df_train['wind_r'] = df_train['wind_speed_10m'].rolling(window=3, min_periods=1).mean()\n",
    "df_val['wind_r']   = df_val['wind_speed_10m'].rolling(window=3, min_periods=1).mean()"
   ],
   "id": "fc6bb049d87a534b",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:46.468409Z",
     "start_time": "2025-05-18T08:08:46.299109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.5: Apply IQR scaling to smoothed Wind Speed\n",
    "for df_ in [df_train, df_val]:\n",
    "    med = df_['wind_r'].rolling(window=window_60d, min_periods=min_periods_60d).median()\n",
    "    q75 = df_['wind_r'].rolling(window=window_60d, min_periods=min_periods_60d).quantile(0.75)\n",
    "    q25 = df_['wind_r'].rolling(window=window_60d, min_periods=min_periods_60d).quantile(0.25)\n",
    "    iqr = q75 - q25\n",
    "    df_['wind_r'] = (df_['wind_r'] - med) / (iqr + eps)"
   ],
   "id": "14ceb67a9fcd4b84",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:46.778695Z",
     "start_time": "2025-05-18T08:08:46.771670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.6: Tranform Precipitation with log1p\n",
    "# Log transformation reduces skew\n",
    "\n",
    "df_train['precip_log'] = np.log1p(df_train['precipitation'])\n",
    "df_val['precip_log']   = np.log1p(df_val['precipitation'])\n"
   ],
   "id": "e711612a6ddf6dca",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:47.290371Z",
     "start_time": "2025-05-18T08:08:47.275715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.7: Apply 12-hour z-score to logged Precipitation\n",
    "# short rolling window captures bursts\n",
    "\n",
    "mean_train = df_train['precip_log'].rolling(window=window_12h, min_periods=min_periods_12h).mean()\n",
    "std_train  = df_train['precip_log'].rolling(window=window_12h, min_periods=min_periods_12h).std()\n",
    "df_train['precip_z_12h'] = (df_train['precip_log'] - mean_train) / (std_train + eps)\n",
    "\n",
    "mean_val = df_val['precip_log'].rolling(window=window_12h, min_periods=min_periods_12h).mean()\n",
    "std_val  = df_val['precip_log'].rolling(window=window_12h, min_periods=min_periods_12h).std()\n",
    "df_val['precip_z_12h'] = (df_val['precip_log'] - mean_val) / (std_val + eps)"
   ],
   "id": "1fcd3166ecadf614",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2 – Time-Based Feature Engineering\n",
    "**Goal**: Add cyclic temporal context to help LSTM-AE learn seasonal and daily rhythms.\n",
    "We encode hour-of-day and month-of-year using sine and cosine pairs\n",
    "to preserve continuity across wraparound points (e.g. 23:00 → 00:00)."
   ],
   "id": "87b0dd47a215d6ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:58.165103Z",
     "start_time": "2025-05-18T08:08:58.149247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2.1: Encode Hour-of-Day Cyclically\n",
    "# Extract hour of day and encode as sine/cosine\n",
    "df_train['hour'] = df_train.index.hour\n",
    "df_train['hour_sin'] = np.sin(2 * np.pi * df_train['hour'] / 24)\n",
    "df_train['hour_cos'] = np.cos(2 * np.pi * df_train['hour'] / 24)\n",
    "\n",
    "df_val['hour'] = df_val.index.hour\n",
    "df_val['hour_sin'] = np.sin(2 * np.pi * df_val['hour'] / 24)\n",
    "df_val['hour_cos'] = np.cos(2 * np.pi * df_val['hour'] / 24)"
   ],
   "id": "e419d8a55bedac4",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:08:58.695566Z",
     "start_time": "2025-05-18T08:08:58.679820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2.2: Encode Month-of-Year Cyclically\n",
    "\n",
    "# Extract month and encode as sine/cosine\n",
    "df_train['month'] = df_train.index.month\n",
    "df_train['month_sin'] = np.sin(2 * np.pi * df_train['month'] / 12)\n",
    "df_train['month_cos'] = np.cos(2 * np.pi * df_train['month'] / 12)\n",
    "\n",
    "df_val['month'] = df_val.index.month\n",
    "df_val['month_sin'] = np.sin(2 * np.pi * df_val['month'] / 12)\n",
    "df_val['month_cos'] = np.cos(2 * np.pi * df_val['month'] / 12)"
   ],
   "id": "81faa94fc8ca7d95",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:00.175578Z",
     "start_time": "2025-05-18T08:09:00.171460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2.3: Define LSTM input features\n",
    "# These include raw weather variables (not transformed) and time features\n",
    "lstm_features = ['temperature_2m', 'surface_pressure', 'wind_speed_10m', 'precipitation']\n",
    "lstm_time_features = ['hour_sin', 'hour_cos', 'month_sin', 'month_cos']"
   ],
   "id": "6e6b08a5f8fb2f81",
   "outputs": [],
   "execution_count": 207
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3 – Isolation Forest Training and Anomaly Scoring\n",
    "**Goal**: Train a single Isolation Forest model using the transformed features in if_features.\n",
    "Use the model to compute anomaly scores for both the training and validation sets.\n",
    "Later, apply different thresholds to these scores for masking and inference."
   ],
   "id": "f2dd5ebe80301532"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:05.371092Z",
     "start_time": "2025-05-18T08:09:05.367093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3.1: Define IF model features\n",
    "if_features = ['temperature_2m_z', 'surface_pressure_z', 'wind_r', 'precip_z_12h']"
   ],
   "id": "4a0aa0787edb29d7",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:07.065408Z",
     "start_time": "2025-05-18T08:09:07.056406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3.2: Drop rows with NaNs in the input features for model training\n",
    "X_train_if = df_train[if_features].dropna()"
   ],
   "id": "c896481ef964c808",
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:08.574708Z",
     "start_time": "2025-05-18T08:09:07.900283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3.3: Train Isolation Forest model\n",
    "if_model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "if_model.fit(X_train_if)"
   ],
   "id": "1d0c4177848675f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.01, random_state=42)"
      ],
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.01, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>IsolationForest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.01, random_state=42)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:13.093263Z",
     "start_time": "2025-05-18T08:09:13.021706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3.4: Save model\n",
    "joblib.dump(preliminary_if,os.path.join(MODEL_OUTPUT_DIR, \"if_model.joblib\"))"
   ],
   "id": "aa809afac92b7322",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/modelling/models/if_model.joblib']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:31.333546Z",
     "start_time": "2025-05-18T08:09:30.997146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3.5: Apply the trained IF model to compute anomaly scores\n",
    "# Scores: higher = more normal, lower = more anomalous\n",
    "\n",
    "df_train_transformed = df_train[if_features].dropna()\n",
    "df_val_transformed = df_val[if_features].dropna()\n",
    "\n",
    "# Score both sets\n",
    "scores_train = if_model.decision_function(df_train_transformed)\n",
    "scores_val   = if_model.decision_function(df_val_transformed)\n",
    "\n",
    "# Store scores in their respective DataFrames\n",
    "df_train.loc[df_train_transformed.index, 'if_score'] = scores_train\n",
    "df_val.loc[df_val_transformed.index, 'if_score'] = scores_val"
   ],
   "id": "9db883c2afe4ff0e",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 4 – Anomaly Masking via Percentile Thresholds\n",
    "**Goal**: Convert continuous IF anomaly scores into binary anomaly flags using different percentile thresholds:\n",
    "\n",
    "- A strict threshold (e.g. 1%) for masking LSTM training data\n",
    "\n",
    "- A more relaxed threshold (e.g. 3%) for validation sequences and inference consistency\n",
    "These labels are only used for sequence filtering, not for model training."
   ],
   "id": "ee61448cb90523d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:34.030148Z",
     "start_time": "2025-05-18T08:09:34.025846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4.1: Define percentile thresholds for anomaly masking\n",
    "mask_threshold_train = 1  # Top 1% most anomalous points in training\n",
    "mask_threshold_val = 3    # Top 3% most anomalous points in validation"
   ],
   "id": "f806b46a27a6ff2b",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:35.604093Z",
     "start_time": "2025-05-18T08:09:35.591755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4.2: Apply Thresholds and Assign Flags\n",
    "\n",
    "# Training set masking (strict)\n",
    "threshold_train = np.percentile(scores_train, mask_threshold_train)\n",
    "df_train['is_anomaly'] = df_train['if_score'] < threshold_train\n",
    "df_train['is_anomaly'] = df_train['is_anomaly'].fillna(False)\n",
    "\n",
    "# Validation set masking (relaxed)\n",
    "threshold_val = np.percentile(scores_val, mask_threshold_val)\n",
    "df_val['is_anomaly'] = df_val['if_score'] < threshold_val\n",
    "df_val['is_anomaly'] = df_val['is_anomaly'].fillna(False)\n"
   ],
   "id": "6372ef5c9ec6196b",
   "outputs": [],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:09:36.630899Z",
     "start_time": "2025-05-18T08:09:36.620847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4.3: Sanity check: How many anomalies were flagged in training and validation?\n",
    "\n",
    "train_anomaly_counts = df_train['is_anomaly'].value_counts()\n",
    "val_anomaly_counts = df_val['is_anomaly'].value_counts()\n",
    "\n",
    "# Absolute counts\n",
    "print(\"Training Set Anomaly Counts:\")\n",
    "print(train_anomaly_counts)\n",
    "\n",
    "print(\"\\nValidation Set Anomaly Counts:\")\n",
    "print(val_anomaly_counts)\n",
    "\n",
    "# Proportions (percent of total)\n",
    "train_anomaly_ratio = df_train['is_anomaly'].mean()\n",
    "val_anomaly_ratio = df_val['is_anomaly'].mean()\n",
    "\n",
    "print(f\"\\nProportion of anomalies in training set: {train_anomaly_ratio:.4f} ({train_anomaly_ratio*100:.2f}%)\")\n",
    "print(f\"Proportion of anomalies in validation set: {val_anomaly_ratio:.4f} ({val_anomaly_ratio*100:.2f}%)\")\n"
   ],
   "id": "f3c4a29c99d18461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Anomaly Counts:\n",
      "is_anomaly\n",
      "False    69433\n",
      "True       695\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Set Anomaly Counts:\n",
      "is_anomaly\n",
      "False    2093\n",
      "True       43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportion of anomalies in training set: 0.0099 (0.99%)\n",
      "Proportion of anomalies in validation set: 0.0201 (2.01%)\n"
     ]
    }
   ],
   "execution_count": 215
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These anomaly flags will be used to filter LSTM sequences in Steps 5 and 6.\n",
    "They are not used directly in training, only for selecting “healthy” sequence windows.\n",
    "This strategy is consistent with semi-supervised pseudo-labelling in literature:\n",
    "\n",
    "- Darban (2024)\n",
    "- Trinh (2022)\n",
    "- Antwarg (2021)"
   ],
   "id": "c2481b5930ceea48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 5 – LSTM-AE Sequence Construction (Training)\n",
    "**Goal**: Extract 30-day (720-hour) sequences from the training set for the LSTM Autoencoder.\n",
    "Sequences must contain no NaNs and no more than 14 anomalous points (~2% of the sequence) to preserve training stability while retaining data coverage."
   ],
   "id": "3ad7f76ce1d1b06b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:31:08.665643Z",
     "start_time": "2025-05-18T08:31:06.291577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5.1: Define Parameters and Initialise\n",
    "\n",
    "# Sequence parameters\n",
    "sequence_length = 720        # 30 days of hourly data\n",
    "sequence_stride = 1          # Slide 1 hour at a time\n",
    "max_allowed_anomalies = 14   # ~2% tolerance per sequence\n",
    "\n",
    "# Features for LSTM-AE\n",
    "lstm_input_cols_all = lstm_features + lstm_time_features\n",
    "\n",
    "# Initialise counters and sequence store\n",
    "debug_counts = {\n",
    "    'total': 0,\n",
    "    'has_nans': 0,\n",
    "    'has_anomalies': 0,\n",
    "    'added': 0\n",
    "}\n",
    "train_sequences = []"
   ],
   "id": "b1568981ff9cacf5",
   "outputs": [],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:33:04.827761Z",
     "start_time": "2025-05-18T08:31:08.740349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5.2: Construct Sequences from df_train\n",
    "\n",
    "# Slide window across full training set\n",
    "for start in range(0, len(df_train) - sequence_length + 1, sequence_stride):\n",
    "    window = df_train.iloc[start:start + sequence_length]\n",
    "    debug_counts['total'] += 1\n",
    "\n",
    "    # Skip if any NaNs (e.g. due to rolling stats)\n",
    "    if window.isna().any().any():\n",
    "        debug_counts['has_nans'] += 1\n",
    "        continue\n",
    "\n",
    "    # Skip if anomaly count exceeds threshold\n",
    "    if window['is_anomaly'].sum() > max_allowed_anomalies:\n",
    "        debug_counts['has_anomalies'] += 1\n",
    "        continue\n",
    "\n",
    "    # If passed all checks, keep sequence\n",
    "    train_sequences.append(window[lstm_input_cols_all].values)\n",
    "    debug_counts['added'] += 1\n",
    "\n",
    "# Report stats\n",
    "print(\"Training sequence construction complete.\")\n",
    "print(f\"Window stats: {debug_counts}\")"
   ],
   "id": "6aea9e37e9be1f49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequence construction complete.\n",
      "Window stats: {'total': 69409, 'has_nans': 719, 'has_anomalies': 9453, 'added': 59237}\n"
     ]
    }
   ],
   "execution_count": 221
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Anomaly Threshold Experiment Summary (Training Set)**\n",
    "\n",
    "We tested how many training sequences could be created with different limits on how many anomalies are allowed per 720-hour (30-day) window.\n",
    "\n",
    "The number of sequences with NaNs at 719 is fully justified by the 720-hour minimum window affecting the first 719 hours due to rolling stats.\n",
    "\n",
    "With a maximum of 14 anomalies per sequence (around 2%), we kept over 59,000 training windows — about 87% of all usable sequences.\n",
    "\n",
    "Reducing the limit to 7 anomalies (around 1%) led to 44,000 valid sequences — a 25% drop. This shows how stricter filtering reduces training data volume.\n",
    "\n",
    "Studies by Darban (2024), Kulkarni et al. (2024), and Trinh (2022) support allowing 1–3% anomaly presence in training. It improves generalisation and avoids underfitting by keeping slight noise and variation. Based on this, we chose 14 anomalies as a balanced threshold for robust LSTM-AE training."
   ],
   "id": "b8ad428137719dd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM training sequences: (59237, 720, 8)\n"
     ]
    }
   ],
   "execution_count": 223,
   "source": [
    "# Step 4.5: Stack into model-ready tensor\n",
    "# Format: (n_sequences, 720, n_features)\n",
    "\n",
    "X_train_lstm = np.stack(train_sequences)\n",
    "print(f\"LSTM training sequences: {X_train_lstm.shape}\")"
   ],
   "id": "fd248c952b9baf78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 6 – LSTM-AE Sequence Construction (Validation)\n",
    "**Goal**: Extract 720-hour sequences from the validation set using the same feature columns, stride, and relaxed masking as in training.\n",
    "This set is used for threshold tuning, early stopping, and SHAP analysis."
   ],
   "id": "408a45564681253f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:41:44.410037Z",
     "start_time": "2025-05-18T08:41:44.405544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6.1: Define Parameters and Initialise\n",
    "\n",
    "val_sequences = []\n",
    "val_debug = {\n",
    "    'total': 0,\n",
    "    'has_nans': 0,\n",
    "    'has_anomalies': 0,\n",
    "    'added': 0\n",
    "}"
   ],
   "id": "dd600e62267b8f99",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:41:47.013685Z",
     "start_time": "2025-05-18T08:41:46.285947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6.2: Slide window across validation set\n",
    "\n",
    "for start in range(0, len(df_val) - sequence_length + 1, sequence_stride):\n",
    "    window = df_val.iloc[start:start + sequence_length]\n",
    "    val_debug['total'] += 1\n",
    "\n",
    "    if window.isna().any().any():\n",
    "        val_debug['has_nans'] += 1\n",
    "        continue\n",
    "\n",
    "    if window['is_anomaly'].sum() > max_allowed_anomalies:\n",
    "        val_debug['has_anomalies'] += 1\n",
    "        continue\n",
    "\n",
    "    val_sequences.append(window[lstm_input_cols_all].values)\n",
    "    val_debug['added'] += 1\n",
    "\n",
    "print(\"Validation sequence construction complete.\")\n",
    "print(f\"Validation window stats: {val_debug}\")\n"
   ],
   "id": "6e98f5dc83ea984e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sequence construction complete.\n",
      "Validation window stats: {'total': 1417, 'has_nans': 719, 'has_anomalies': 636, 'added': 62}\n"
     ]
    }
   ],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T08:41:54.110930Z",
     "start_time": "2025-05-18T08:41:54.101734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6.3: Final shape: (n_val_sequences, 720, n_features)\n",
    "X_val_lstm = np.stack(val_sequences)\n",
    "print(f\"LSTM validation sequences: {X_val_lstm.shape}\")"
   ],
   "id": "e0f1a3c02b55c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM validation sequences: (62, 720, 8)\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 7 – Save Processed Sequences and Transformed Data\n",
    "**Goal**: Persist key outputs including preprocessed training and validation dataframes, and their corresponding LSTM-AE tensors.\n",
    "This allows reuse for model training, threshold tuning, and interpretability tasks without re-running all preprocessing steps."
   ],
   "id": "e6c2f03351e07d37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:22:06.465672Z",
     "start_time": "2025-05-18T12:21:24.218699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save transformed DataFrames (optional but useful for SHAP/debugging)\n",
    "df_train.to_csv(os.path.join(MODEL_INPIT_OUTPUT_DIR, 'df_train_preprocessed.csv'))\n",
    "df_val.to_csv(os.path.join(MODEL_INPIT_OUTPUT_DIR, 'df_val_preprocessed.csv'))\n",
    "\n",
    "# Save LSTM-AE ready sequences\n",
    "np.save(os.path.join(MODEL_INPIT_OUTPUT_DIR, 'X_train_lstm.npy'), X_train_lstm)\n",
    "np.save(os.path.join(MODEL_INPIT_OUTPUT_DIR, 'X_val_lstm.npy'), X_val_lstm)"
   ],
   "id": "b6bd7413118fd30d",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 8 – Train the LSTM Autoencoder\n",
    "**Goal**: Train an LSTM-based autoencoder on the 720-hour sequences (X_train_lstm) to learn normal weather patterns.\n",
    "During evaluation, sequences that produce high reconstruction error will be considered anomalous."
   ],
   "id": "c8d90784b4beca63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T12:44:59.708447Z",
     "start_time": "2025-05-18T12:44:59.346794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 8.1: Define the LSTM-AE Architecture\n",
    "\n",
    "# Get sequence and feature dimensions\n",
    "timesteps = X_train_lstm.shape[1]  # e.g. 720\n",
    "n_features = X_train_lstm.shape[2] # e.g. 8\n",
    "\n",
    "# Define model\n",
    "input_layer = Input(shape=(timesteps, n_features))\n",
    "\n",
    "# Encoder\n",
    "encoded = LSTM(64, activation='tanh', return_sequences=True)(input_layer)\n",
    "encoded = LSTM(32, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "# Bottleneck\n",
    "bottleneck = RepeatVector(timesteps)(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = LSTM(32, activation='tanh', return_sequences=True)(bottleneck)\n",
    "decoded = LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(n_features))(decoded)\n",
    "\n",
    "# Assemble\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
    "\n",
    "# Print summary\n",
    "autoencoder.summary()"
   ],
   "id": "12ea1302fb9842fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m720\u001B[0m, \u001B[38;5;34m8\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m720\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │        \u001B[38;5;34m18,688\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │        \u001B[38;5;34m12,416\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001B[38;5;33mRepeatVector\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m720\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m720\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │         \u001B[38;5;34m8,320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m720\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │        \u001B[38;5;34m24,832\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m720\u001B[0m, \u001B[38;5;34m8\u001B[0m)         │           \u001B[38;5;34m520\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m64,776\u001B[0m (253.03 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,776</span> (253.03 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m64,776\u001B[0m (253.03 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,776</span> (253.03 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 233
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 9 – Train the LSTM Autoencoder with Early Stopping <br>\n",
    "**Goal**: Train the LSTM-AE to reconstruct normal sequences using MAE loss.\n",
    "Early stopping prevents overfitting by halting training when validation loss no longer improves."
   ],
   "id": "ce12a503332f08dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Training Configuration Summary**\n",
    "\n",
    "We trained the LSTM Autoencoder using the following settings:\n",
    "\n",
    "Loss = 'mae' (Mean Absolute Error):\n",
    "MAE is used to measure how closely the model can reconstruct each value in a sequence. It is more robust to outliers than MSE and works well for threshold-based anomaly detection (Trinh, 2022; Darban, 2024).\n",
    "\n",
    "Batch size = 32:\n",
    "This is a typical batch size for time-series data. It allows the model to learn temporal dependencies while maintaining training efficiency (Kulkarni et al., 2024).\n",
    "\n",
    "Epochs = 100 with early stopping (patience = 5):\n",
    "Early stopping halts training when the validation loss stops improving. This prevents overfitting and saves resources (Bâra et al., 2024).\n",
    "\n",
    "ModelCheckpoint:\n",
    "We saved the best-performing model (based on validation loss) to a .h5 file for reuse. This avoids retraining and supports downstream analysis (Antwarg et al., 2021).\n",
    "\n",
    "Shuffle = True:\n",
    "Shuffling training sequences prevents the model from overfitting to local trends and improves generalisation (Darban, 2024)."
   ],
   "id": "42deab7341c94a7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:34:37.341649Z",
     "start_time": "2025-05-18T12:57:13.459166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='outputs/modelling/models/lstm_ae_best.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = autoencoder.fit(\n",
    "    X_train_lstm, X_train_lstm,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_lstm, X_val_lstm),\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE Loss\")\n",
    "plt.title(\"LSTM-AE Training Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fb9daf41db1eaede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[235]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m      4\u001B[39m model_checkpoint = ModelCheckpoint(\n\u001B[32m      5\u001B[39m     filepath=\u001B[33m'\u001B[39m\u001B[33moutputs/modelling/models/lstm_ae_best.h5\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m      6\u001B[39m     monitor=\u001B[33m'\u001B[39m\u001B[33mval_loss\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m      7\u001B[39m     save_best_only=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      8\u001B[39m     verbose=\u001B[32m1\u001B[39m\n\u001B[32m      9\u001B[39m )\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m history = \u001B[43mautoencoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_train_lstm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_lstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val_lstm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_lstm\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_checkpoint\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\n\u001B[32m     20\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Plot training history\u001B[39;00m\n\u001B[32m     23\u001B[39m plt.figure(figsize=(\u001B[32m8\u001B[39m, \u001B[32m4\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m    370\u001B[39m     callbacks.on_train_batch_begin(step)\n\u001B[32m--> \u001B[39m\u001B[32m371\u001B[39m     logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    372\u001B[39m     callbacks.on_train_batch_end(step, logs)\n\u001B[32m    373\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stop_training:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.function\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunction\u001B[39m(iterator):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    217\u001B[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001B[32m    218\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m         opt_outputs = \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs.has_value():\n\u001B[32m    221\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    875\u001B[39m \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    876\u001B[39m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[32m    877\u001B[39m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m878\u001B[39m results = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._created_variables:\n\u001B[32m    882\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCreating variables on a non-first call to a function\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    883\u001B[39m                    \u001B[33m\"\u001B[39m\u001B[33m decorated with tf.function.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\COMP1884-Group6-Codebase\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 235
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "636a31df87fe747f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
